{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "import requests\n",
    "import collections\n",
    "import io\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import text_helpers\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a saving directory if it doesn't exist\n",
    "data_folder_name = 'temp'\n",
    "if not os.path.exists(data_folder_name):\n",
    "    os.makedirs(data_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "vocabulary_size = 7500\n",
    "generations = 100000\n",
    "model_learning_rate = 0.001\n",
    "\n",
    "embedding_size = 200   # Word embedding size\n",
    "doc_embedding_size = 100   # Document embedding size\n",
    "concatenated_size = embedding_size + doc_embedding_size\n",
    "\n",
    "num_sampled = int(batch_size/2)    # Number of negative examples to sample.\n",
    "window_size = 3       # How many words to consider to the left.\n",
    "\n",
    "# Add checkpoints to training\n",
    "save_embeddings_every = 5000\n",
    "print_valid_every = 5000\n",
    "print_loss_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Normalizing Text Data\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Declare stop words\n",
    "#stops = stopwords.words('english')\n",
    "stops = []\n",
    "\n",
    "# We pick a few test words for validation.\n",
    "valid_words = ['love', 'hate', 'happy', 'sad', 'man', 'woman']\n",
    "# Later we will have to transform these into indices\n",
    "\n",
    "# Load the movie review data\n",
    "print('Loading Data')\n",
    "texts, target = text_helpers.load_movie_data()\n",
    "\n",
    "# Normalize text\n",
    "print('Normalizing Text Data')\n",
    "texts = text_helpers.normalize_text(texts, stops)\n",
    "\n",
    "# Texts must contain at least 3 words\n",
    "target = [target[ix] for ix, x in enumerate(texts) if len(x.split()) > window_size]\n",
    "texts = [x for x in texts if len(x.split()) > window_size]    \n",
    "assert(len(target)==len(texts))\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dictionary\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Build our data set and dictionaries\n",
    "print('Creating Dictionary')\n",
    "word_dictionary = text_helpers.build_dictionary(texts, vocabulary_size)\n",
    "word_dictionary_rev = dict(zip(word_dictionary.values(), word_dictionary.keys()))\n",
    "text_data = text_helpers.text_to_numbers(texts, word_dictionary)\n",
    "\n",
    "# Get validation word keys\n",
    "valid_examples = [word_dictionary[x] for x in valid_words]\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Creating Model')\n",
    "# Define Embeddings:\n",
    "embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "doc_embeddings = tf.Variable(tf.random_uniform([len(texts), doc_embedding_size], -1.0, 1.0))\n",
    "\n",
    "# NCE loss parameters\n",
    "nce_weights = tf.Variable(tf.truncated_normal([vocabulary_size, concatenated_size],\n",
    "                                               stddev=1.0 / np.sqrt(concatenated_size)))\n",
    "nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "# Create data/target placeholders\n",
    "x_inputs = tf.placeholder(tf.int32, shape=[None, window_size + 1]) # plus 1 for doc index\n",
    "y_target = tf.placeholder(tf.int32, shape=[None, 1])\n",
    "valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "# Lookup the word embedding\n",
    "# Add together element embeddings in window:\n",
    "embed = tf.zeros([batch_size, embedding_size])\n",
    "for element in range(window_size):\n",
    "    embed += tf.nn.embedding_lookup(embeddings, x_inputs[:, element])\n",
    "\n",
    "doc_indices = tf.slice(x_inputs, [0,window_size],[batch_size,1])\n",
    "doc_embed = tf.nn.embedding_lookup(doc_embeddings,doc_indices)\n",
    "\n",
    "# concatenate embeddings\n",
    "final_embed = tf.concat(axis=1, values=[embed, tf.squeeze(doc_embed)])\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get loss from prediction\n",
    "loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weights,\n",
    "                                     biases=nce_biases,\n",
    "                                     labels=y_target,\n",
    "                                     inputs=final_embed,\n",
    "                                     num_sampled=num_sampled,\n",
    "                                     num_classes=vocabulary_size))\n",
    "                                     \n",
    "# Create optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=model_learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "# Cosine similarity between words\n",
    "norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "normalized_embeddings = embeddings / norm\n",
    "valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "\n",
    "# Create model saving operation\n",
    "saver = tf.train.Saver({\"embeddings\": embeddings, \"doc_embeddings\": doc_embeddings})\n",
    "\n",
    "#Add variable initializer.\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Loss at step 100 : 26.123146057128906\n",
      "Loss at step 200 : 21.973981857299805\n",
      "Loss at step 300 : 14.549206733703613\n",
      "Loss at step 400 : 18.90227699279785\n",
      "Loss at step 500 : 14.576988220214844\n",
      "Loss at step 600 : 16.81222152709961\n",
      "Loss at step 700 : 24.745500564575195\n",
      "Loss at step 800 : 10.66199779510498\n",
      "Loss at step 900 : 21.346149444580078\n",
      "Loss at step 1000 : 18.498979568481445\n",
      "Loss at step 1100 : 24.30424690246582\n",
      "Loss at step 1200 : 16.300081253051758\n",
      "Loss at step 1300 : 19.17396354675293\n",
      "Loss at step 1400 : 18.970230102539062\n",
      "Loss at step 1500 : 13.918855667114258\n",
      "Loss at step 1600 : 19.595441818237305\n",
      "Loss at step 1700 : 16.918054580688477\n",
      "Loss at step 1800 : 18.993946075439453\n",
      "Loss at step 1900 : 12.8231840133667\n",
      "Loss at step 2000 : 21.682323455810547\n",
      "Loss at step 2100 : 18.36751937866211\n",
      "Loss at step 2200 : 20.192577362060547\n",
      "Loss at step 2300 : 15.472284317016602\n",
      "Loss at step 2400 : 25.392480850219727\n",
      "Loss at step 2500 : 15.340847969055176\n",
      "Loss at step 2600 : 17.002729415893555\n",
      "Loss at step 2700 : 17.246822357177734\n",
      "Loss at step 2800 : 20.37779998779297\n",
      "Loss at step 2900 : 18.801050186157227\n",
      "Loss at step 3000 : 20.880525588989258\n",
      "Loss at step 3100 : 18.63888168334961\n",
      "Loss at step 3200 : 15.608113288879395\n",
      "Loss at step 3300 : 16.658124923706055\n",
      "Loss at step 3400 : 19.46840476989746\n",
      "Loss at step 3500 : 21.892738342285156\n",
      "Loss at step 3600 : 16.971115112304688\n",
      "Loss at step 3700 : 15.70079517364502\n",
      "Loss at step 3800 : 19.303308486938477\n",
      "Loss at step 3900 : 19.312889099121094\n",
      "Loss at step 4000 : 20.077472686767578\n",
      "Loss at step 4100 : 18.579063415527344\n",
      "Loss at step 4200 : 16.680307388305664\n",
      "Loss at step 4300 : 25.229764938354492\n",
      "Loss at step 4400 : 20.182973861694336\n",
      "Loss at step 4500 : 20.42719268798828\n",
      "Loss at step 4600 : 19.862422943115234\n",
      "Loss at step 4700 : 16.95149803161621\n",
      "Loss at step 4800 : 18.233861923217773\n",
      "Loss at step 4900 : 16.248376846313477\n",
      "Loss at step 5000 : 15.2088041305542\n",
      "Nearest to love: a, like, in, the, are,\n",
      "Nearest to hate: thick, static, descends, remarkable, crossroads,\n",
      "Nearest to happy: proportions, bumper, content, in, band,\n",
      "Nearest to sad: gives, adolescent, masterful, end, us,\n",
      "Nearest to man: are, enough, of, touching, accurate,\n",
      "Nearest to woman: art, scathing, what, steers, nonsense,\n",
      "Model saved in file: C:\\Users\\Evan\\Documents\\TensorflowExamples\\temp\\doc2vec_movie_embeddings.ckpt\n",
      "Loss at step 5100 : 17.343914031982422\n",
      "Loss at step 5200 : 17.412649154663086\n",
      "Loss at step 5300 : 16.827280044555664\n",
      "Loss at step 5400 : 16.372600555419922\n",
      "Loss at step 5500 : 17.057300567626953\n",
      "Loss at step 5600 : 19.160118103027344\n",
      "Loss at step 5700 : 17.92497444152832\n",
      "Loss at step 5800 : 17.406469345092773\n",
      "Loss at step 5900 : 17.620134353637695\n",
      "Loss at step 6000 : 18.383230209350586\n",
      "Loss at step 6100 : 21.657527923583984\n",
      "Loss at step 6200 : 16.23993492126465\n",
      "Loss at step 6300 : 16.04213523864746\n",
      "Loss at step 6400 : 18.59441566467285\n",
      "Loss at step 6500 : 17.284631729125977\n",
      "Loss at step 6600 : 16.984399795532227\n",
      "Loss at step 6700 : 18.766040802001953\n",
      "Loss at step 6800 : 15.852431297302246\n",
      "Loss at step 6900 : 19.27203369140625\n",
      "Loss at step 7000 : 14.932402610778809\n",
      "Loss at step 7100 : 15.886384963989258\n",
      "Loss at step 7200 : 16.84911346435547\n",
      "Loss at step 7300 : 24.304845809936523\n",
      "Loss at step 7400 : 16.0150203704834\n",
      "Loss at step 7500 : 16.773624420166016\n",
      "Loss at step 7600 : 22.884906768798828\n",
      "Loss at step 7700 : 17.848691940307617\n",
      "Loss at step 7800 : 13.353790283203125\n",
      "Loss at step 7900 : 15.990838050842285\n",
      "Loss at step 8000 : 25.986106872558594\n",
      "Loss at step 8100 : 21.147287368774414\n",
      "Loss at step 8200 : 17.47405433654785\n",
      "Loss at step 8300 : 21.821744918823242\n",
      "Loss at step 8400 : 17.16800308227539\n",
      "Loss at step 8500 : 16.03536033630371\n",
      "Loss at step 8600 : 15.343825340270996\n",
      "Loss at step 8700 : 20.976736068725586\n",
      "Loss at step 8800 : 14.192248344421387\n",
      "Loss at step 8900 : 19.805212020874023\n",
      "Loss at step 9000 : 20.671480178833008\n",
      "Loss at step 9100 : 17.667097091674805\n",
      "Loss at step 9200 : 16.718856811523438\n",
      "Loss at step 9300 : 15.588932991027832\n",
      "Loss at step 9400 : 16.12760353088379\n",
      "Loss at step 9500 : 16.927875518798828\n",
      "Loss at step 9600 : 17.81974220275879\n",
      "Loss at step 9700 : 20.530221939086914\n",
      "Loss at step 9800 : 27.023855209350586\n",
      "Loss at step 9900 : 22.035463333129883\n",
      "Loss at step 10000 : 19.56939125061035\n",
      "Nearest to love: a, like, in, the, are,\n",
      "Nearest to hate: thick, static, descends, remarkable, crossroads,\n",
      "Nearest to happy: proportions, bumper, in, on, content,\n",
      "Nearest to sad: gives, adolescent, masterful, end, us,\n",
      "Nearest to man: are, enough, of, touching, accurate,\n",
      "Nearest to woman: art, what, scathing, steers, nonsense,\n",
      "Model saved in file: C:\\Users\\Evan\\Documents\\TensorflowExamples\\temp\\doc2vec_movie_embeddings.ckpt\n",
      "Loss at step 10100 : 18.166156768798828\n",
      "Loss at step 10200 : 23.658180236816406\n",
      "Loss at step 10300 : 15.666886329650879\n",
      "Loss at step 10400 : 14.422706604003906\n",
      "Loss at step 10500 : 19.951129913330078\n",
      "Loss at step 10600 : 17.129371643066406\n",
      "Loss at step 10700 : 18.17593002319336\n",
      "Loss at step 10800 : 21.693857192993164\n",
      "Loss at step 10900 : 14.663475036621094\n",
      "Loss at step 11000 : 11.743123054504395\n",
      "Loss at step 11100 : 19.863815307617188\n",
      "Loss at step 11200 : 21.91252899169922\n",
      "Loss at step 11300 : 17.397859573364258\n",
      "Loss at step 11400 : 16.08356475830078\n",
      "Loss at step 11500 : 19.537757873535156\n",
      "Loss at step 11600 : 16.128311157226562\n",
      "Loss at step 11700 : 16.5145320892334\n",
      "Loss at step 11800 : 13.112576484680176\n",
      "Loss at step 11900 : 18.991960525512695\n",
      "Loss at step 12000 : 20.635740280151367\n",
      "Loss at step 12100 : 14.645259857177734\n",
      "Loss at step 12200 : 17.125261306762695\n",
      "Loss at step 12300 : 17.68193817138672\n",
      "Loss at step 12400 : 14.610204696655273\n",
      "Loss at step 12500 : 15.124802589416504\n",
      "Loss at step 12600 : 20.63994026184082\n",
      "Loss at step 12700 : 18.371736526489258\n",
      "Loss at step 12800 : 15.869222640991211\n",
      "Loss at step 12900 : 18.020002365112305\n",
      "Loss at step 13000 : 16.817277908325195\n",
      "Loss at step 13100 : 16.14081382751465\n",
      "Loss at step 13200 : 16.754098892211914\n",
      "Loss at step 13300 : 19.928531646728516\n",
      "Loss at step 13400 : 17.78459358215332\n",
      "Loss at step 13500 : 20.876344680786133\n",
      "Loss at step 13600 : 14.272287368774414\n",
      "Loss at step 13700 : 16.860668182373047\n",
      "Loss at step 13800 : 17.295230865478516\n",
      "Loss at step 13900 : 15.063400268554688\n",
      "Loss at step 14000 : 18.0753116607666\n",
      "Loss at step 14100 : 16.32578468322754\n",
      "Loss at step 14200 : 15.482585906982422\n",
      "Loss at step 14300 : 19.843772888183594\n",
      "Loss at step 14400 : 14.522745132446289\n",
      "Loss at step 14500 : 16.18143081665039\n",
      "Loss at step 14600 : 13.710371971130371\n",
      "Loss at step 14700 : 22.48881721496582\n",
      "Loss at step 14800 : 18.9060001373291\n",
      "Loss at step 14900 : 19.39402198791504\n",
      "Loss at step 15000 : 16.97438621520996\n",
      "Nearest to love: like, a, in, the, are,\n",
      "Nearest to hate: thick, static, descends, remarkable, crossroads,\n",
      "Nearest to happy: proportions, bumper, in, on, content,\n",
      "Nearest to sad: gives, adolescent, masterful, end, us,\n",
      "Nearest to man: are, enough, of, touching, accurate,\n",
      "Nearest to woman: art, what, scathing, steers, nonsense,\n",
      "Model saved in file: C:\\Users\\Evan\\Documents\\TensorflowExamples\\temp\\doc2vec_movie_embeddings.ckpt\n",
      "Loss at step 15100 : 15.106084823608398\n",
      "Loss at step 15200 : 18.11186408996582\n",
      "Loss at step 15300 : 15.314820289611816\n",
      "Loss at step 15400 : 16.17618179321289\n",
      "Loss at step 15500 : 19.647977828979492\n",
      "Loss at step 15600 : 15.741188049316406\n",
      "Loss at step 15700 : 15.333110809326172\n",
      "Loss at step 15800 : 18.365570068359375\n",
      "Loss at step 15900 : 13.835772514343262\n",
      "Loss at step 16000 : 18.533714294433594\n",
      "Loss at step 16100 : 19.848926544189453\n",
      "Loss at step 16200 : 22.09221649169922\n",
      "Loss at step 16300 : 16.513654708862305\n",
      "Loss at step 16400 : 15.437546730041504\n",
      "Loss at step 16500 : 19.319406509399414\n",
      "Loss at step 16600 : 21.30915641784668\n",
      "Loss at step 16700 : 15.568001747131348\n",
      "Loss at step 16800 : 20.03951644897461\n",
      "Loss at step 16900 : 16.969696044921875\n",
      "Loss at step 17000 : 16.028417587280273\n",
      "Loss at step 17100 : 14.788804054260254\n",
      "Loss at step 17200 : 13.335716247558594\n",
      "Loss at step 17300 : 22.48526382446289\n",
      "Loss at step 17400 : 11.913320541381836\n",
      "Loss at step 17500 : 13.855618476867676\n",
      "Loss at step 17600 : 20.633949279785156\n",
      "Loss at step 17700 : 13.583147048950195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 17800 : 15.908406257629395\n",
      "Loss at step 17900 : 18.37805938720703\n",
      "Loss at step 18000 : 18.530357360839844\n",
      "Loss at step 18100 : 17.730710983276367\n",
      "Loss at step 18200 : 15.952566146850586\n",
      "Loss at step 18300 : 17.059362411499023\n",
      "Loss at step 18400 : 18.240859985351562\n",
      "Loss at step 18500 : 17.84923553466797\n",
      "Loss at step 18600 : 16.863605499267578\n",
      "Loss at step 18700 : 23.04124641418457\n",
      "Loss at step 18800 : 17.826915740966797\n",
      "Loss at step 18900 : 13.707048416137695\n",
      "Loss at step 19000 : 14.692239761352539\n",
      "Loss at step 19100 : 20.658960342407227\n",
      "Loss at step 19200 : 15.308323860168457\n",
      "Loss at step 19300 : 18.180631637573242\n",
      "Loss at step 19400 : 19.274953842163086\n",
      "Loss at step 19500 : 19.886987686157227\n",
      "Loss at step 19600 : 14.36757755279541\n",
      "Loss at step 19700 : 17.550872802734375\n",
      "Loss at step 19800 : 18.948026657104492\n",
      "Loss at step 19900 : 19.043495178222656\n",
      "Loss at step 20000 : 17.562175750732422\n",
      "Nearest to love: like, in, a, the, are,\n",
      "Nearest to hate: thick, static, descends, remarkable, crossroads,\n",
      "Nearest to happy: proportions, bumper, in, on, content,\n",
      "Nearest to sad: gives, adolescent, masterful, us, end,\n",
      "Nearest to man: are, enough, of, touching, very,\n",
      "Nearest to woman: art, what, scathing, steers, nonsense,\n",
      "Model saved in file: C:\\Users\\Evan\\Documents\\TensorflowExamples\\temp\\doc2vec_movie_embeddings.ckpt\n",
      "Loss at step 20100 : 17.892526626586914\n",
      "Loss at step 20200 : 16.105567932128906\n",
      "Loss at step 20300 : 18.193159103393555\n",
      "Loss at step 20400 : 14.116559028625488\n",
      "Loss at step 20500 : 20.01349449157715\n",
      "Loss at step 20600 : 12.556168556213379\n",
      "Loss at step 20700 : 15.724424362182617\n",
      "Loss at step 20800 : 17.14719581604004\n",
      "Loss at step 20900 : 17.208101272583008\n",
      "Loss at step 21000 : 16.55585479736328\n",
      "Loss at step 21100 : 17.319276809692383\n",
      "Loss at step 21200 : 18.82540512084961\n",
      "Loss at step 21300 : 15.109667778015137\n",
      "Loss at step 21400 : 14.95926570892334\n",
      "Loss at step 21500 : 16.77448081970215\n",
      "Loss at step 21600 : 15.431347846984863\n",
      "Loss at step 21700 : 12.892594337463379\n",
      "Loss at step 21800 : 15.367300987243652\n",
      "Loss at step 21900 : 14.366878509521484\n",
      "Loss at step 22000 : 24.963851928710938\n",
      "Loss at step 22100 : 13.210350036621094\n",
      "Loss at step 22200 : 16.011734008789062\n",
      "Loss at step 22300 : 12.182734489440918\n",
      "Loss at step 22400 : 19.767656326293945\n",
      "Loss at step 22500 : 16.10038948059082\n",
      "Loss at step 22600 : 15.806973457336426\n",
      "Loss at step 22700 : 12.534453392028809\n",
      "Loss at step 22800 : 20.615684509277344\n",
      "Loss at step 22900 : 20.03372573852539\n",
      "Loss at step 23000 : 18.898874282836914\n",
      "Loss at step 23100 : 12.100589752197266\n",
      "Loss at step 23200 : 17.514917373657227\n",
      "Loss at step 23300 : 14.366988182067871\n",
      "Loss at step 23400 : 20.199922561645508\n",
      "Loss at step 23500 : 17.584516525268555\n",
      "Loss at step 23600 : 15.040194511413574\n",
      "Loss at step 23700 : 15.258593559265137\n",
      "Loss at step 23800 : 17.709308624267578\n",
      "Loss at step 23900 : 21.18403434753418\n",
      "Loss at step 24000 : 17.31915855407715\n",
      "Loss at step 24100 : 15.798795700073242\n",
      "Loss at step 24200 : 18.205217361450195\n",
      "Loss at step 24300 : 18.35650062561035\n",
      "Loss at step 24400 : 18.2135066986084\n",
      "Loss at step 24500 : 14.933693885803223\n",
      "Loss at step 24600 : 19.390073776245117\n",
      "Loss at step 24700 : 16.40982437133789\n",
      "Loss at step 24800 : 17.53239631652832\n",
      "Loss at step 24900 : 14.09696102142334\n",
      "Loss at step 25000 : 12.870108604431152\n",
      "Nearest to love: like, in, a, the, are,\n",
      "Nearest to hate: thick, static, descends, remarkable, crossroads,\n",
      "Nearest to happy: proportions, bumper, in, on, content,\n",
      "Nearest to sad: gives, adolescent, masterful, us, end,\n",
      "Nearest to man: are, enough, of, touching, very,\n",
      "Nearest to woman: art, what, scathing, steers, special,\n",
      "Model saved in file: C:\\Users\\Evan\\Documents\\TensorflowExamples\\temp\\doc2vec_movie_embeddings.ckpt\n",
      "Loss at step 25100 : 17.113914489746094\n",
      "Loss at step 25200 : 18.90462303161621\n",
      "Loss at step 25300 : 16.158140182495117\n",
      "Loss at step 25400 : 13.542609214782715\n",
      "Loss at step 25500 : 11.519899368286133\n",
      "Loss at step 25600 : 15.653538703918457\n",
      "Loss at step 25700 : 12.069695472717285\n",
      "Loss at step 25800 : 19.72105598449707\n",
      "Loss at step 25900 : 13.431167602539062\n",
      "Loss at step 26000 : 16.081897735595703\n",
      "Loss at step 26100 : 21.212600708007812\n",
      "Loss at step 26200 : 17.52853012084961\n",
      "Loss at step 26300 : 18.476696014404297\n",
      "Loss at step 26400 : 15.271268844604492\n",
      "Loss at step 26500 : 15.98861312866211\n",
      "Loss at step 26600 : 20.03885269165039\n",
      "Loss at step 26700 : 13.308306694030762\n",
      "Loss at step 26800 : 18.307979583740234\n",
      "Loss at step 26900 : 14.989093780517578\n",
      "Loss at step 27000 : 17.898914337158203\n",
      "Loss at step 27100 : 19.44828987121582\n",
      "Loss at step 27200 : 16.200153350830078\n",
      "Loss at step 27300 : 18.579139709472656\n",
      "Loss at step 27400 : 13.52958869934082\n",
      "Loss at step 27500 : 15.425812721252441\n",
      "Loss at step 27600 : 14.587104797363281\n",
      "Loss at step 27700 : 16.66583251953125\n",
      "Loss at step 27800 : 16.928516387939453\n",
      "Loss at step 27900 : 17.914554595947266\n",
      "Loss at step 28000 : 14.044651985168457\n",
      "Loss at step 28100 : 12.177896499633789\n",
      "Loss at step 28200 : 17.40594482421875\n",
      "Loss at step 28300 : 20.471691131591797\n",
      "Loss at step 28400 : 16.06709098815918\n",
      "Loss at step 28500 : 12.377398490905762\n",
      "Loss at step 28600 : 16.199983596801758\n",
      "Loss at step 28700 : 18.632503509521484\n",
      "Loss at step 28800 : 14.029603958129883\n",
      "Loss at step 28900 : 15.491992950439453\n",
      "Loss at step 29000 : 16.67562484741211\n",
      "Loss at step 29100 : 27.273422241210938\n",
      "Loss at step 29200 : 12.144083976745605\n",
      "Loss at step 29300 : 17.098669052124023\n",
      "Loss at step 29400 : 15.690937042236328\n",
      "Loss at step 29500 : 16.7557430267334\n",
      "Loss at step 29600 : 14.621740341186523\n",
      "Loss at step 29700 : 16.193843841552734\n",
      "Loss at step 29800 : 18.029428482055664\n",
      "Loss at step 29900 : 14.246297836303711\n",
      "Loss at step 30000 : 17.813894271850586\n",
      "Nearest to love: like, in, a, are, the,\n",
      "Nearest to hate: thick, static, descends, remarkable, crossroads,\n",
      "Nearest to happy: proportions, bumper, in, on, content,\n",
      "Nearest to sad: gives, adolescent, masterful, us, end,\n",
      "Nearest to man: are, enough, of, touching, very,\n",
      "Nearest to woman: art, what, scathing, steers, special,\n",
      "Model saved in file: C:\\Users\\Evan\\Documents\\TensorflowExamples\\temp\\doc2vec_movie_embeddings.ckpt\n",
      "Loss at step 30100 : 20.233224868774414\n",
      "Loss at step 30200 : 15.703391075134277\n",
      "Loss at step 30300 : 13.44714641571045\n",
      "Loss at step 30400 : 20.343629837036133\n",
      "Loss at step 30500 : 20.858386993408203\n",
      "Loss at step 30600 : 20.34195327758789\n",
      "Loss at step 30700 : 15.54393196105957\n",
      "Loss at step 30800 : 17.61391830444336\n",
      "Loss at step 30900 : 15.992528915405273\n",
      "Loss at step 31000 : 23.736845016479492\n",
      "Loss at step 31100 : 16.793598175048828\n",
      "Loss at step 31200 : 18.43885612487793\n",
      "Loss at step 31300 : 18.277217864990234\n",
      "Loss at step 31400 : 19.518442153930664\n",
      "Loss at step 31500 : 13.553603172302246\n",
      "Loss at step 31600 : 14.01783275604248\n",
      "Loss at step 31700 : 12.17394733428955\n",
      "Loss at step 31800 : 10.759709358215332\n",
      "Loss at step 31900 : 16.845510482788086\n",
      "Loss at step 32000 : 18.58452033996582\n",
      "Loss at step 32100 : 14.224658012390137\n",
      "Loss at step 32200 : 18.254924774169922\n",
      "Loss at step 32300 : 13.140117645263672\n",
      "Loss at step 32400 : 15.452183723449707\n",
      "Loss at step 32500 : 16.203107833862305\n",
      "Loss at step 32600 : 14.598222732543945\n",
      "Loss at step 32700 : 15.641369819641113\n",
      "Loss at step 32800 : 15.526078224182129\n",
      "Loss at step 32900 : 16.868600845336914\n",
      "Loss at step 33000 : 14.14001750946045\n",
      "Loss at step 33100 : 16.5647029876709\n",
      "Loss at step 33200 : 15.245439529418945\n",
      "Loss at step 33300 : 15.974499702453613\n",
      "Loss at step 33400 : 16.50203514099121\n",
      "Loss at step 33500 : 18.77112579345703\n",
      "Loss at step 33600 : 14.69245719909668\n",
      "Loss at step 33700 : 14.626011848449707\n",
      "Loss at step 33800 : 10.977083206176758\n",
      "Loss at step 33900 : 13.85583782196045\n",
      "Loss at step 34000 : 11.646578788757324\n",
      "Loss at step 34100 : 14.74941635131836\n",
      "Loss at step 34200 : 14.424237251281738\n",
      "Loss at step 34300 : 16.474428176879883\n",
      "Loss at step 34400 : 17.757957458496094\n",
      "Loss at step 34500 : 15.081443786621094\n",
      "Loss at step 34600 : 18.06484603881836\n",
      "Loss at step 34700 : 14.378484725952148\n",
      "Loss at step 34800 : 19.042179107666016\n",
      "Loss at step 34900 : 15.476211547851562\n",
      "Loss at step 35000 : 13.063322067260742\n",
      "Nearest to love: like, in, a, are, the,\n",
      "Nearest to hate: thick, static, descends, remarkable, crossroads,\n",
      "Nearest to happy: proportions, bumper, in, on, content,\n",
      "Nearest to sad: gives, adolescent, masterful, us, end,\n",
      "Nearest to man: are, enough, of, touching, very,\n",
      "Nearest to woman: art, what, scathing, steers, special,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: C:\\Users\\Evan\\Documents\\TensorflowExamples\\temp\\doc2vec_movie_embeddings.ckpt\n",
      "Loss at step 35100 : 16.262231826782227\n",
      "Loss at step 35200 : 15.797905921936035\n",
      "Loss at step 35300 : 20.209421157836914\n",
      "Loss at step 35400 : 14.266108512878418\n",
      "Loss at step 35500 : 19.046253204345703\n",
      "Loss at step 35600 : 17.642086029052734\n",
      "Loss at step 35700 : 17.589786529541016\n",
      "Loss at step 35800 : 14.884262084960938\n",
      "Loss at step 35900 : 11.349271774291992\n",
      "Loss at step 36000 : 17.800336837768555\n",
      "Loss at step 36100 : 14.63790512084961\n",
      "Loss at step 36200 : 17.14775848388672\n",
      "Loss at step 36300 : 13.55642032623291\n",
      "Loss at step 36400 : 11.982966423034668\n",
      "Loss at step 36500 : 15.095621109008789\n",
      "Loss at step 36600 : 14.349234580993652\n",
      "Loss at step 36700 : 13.643282890319824\n",
      "Loss at step 36800 : 13.909433364868164\n",
      "Loss at step 36900 : 13.468755722045898\n",
      "Loss at step 37000 : 15.487139701843262\n",
      "Loss at step 37100 : 13.6512451171875\n",
      "Loss at step 37200 : 15.477781295776367\n",
      "Loss at step 37300 : 14.945225715637207\n",
      "Loss at step 37400 : 15.709919929504395\n",
      "Loss at step 37500 : 17.356935501098633\n",
      "Loss at step 37600 : 15.628392219543457\n",
      "Loss at step 37700 : 18.292293548583984\n",
      "Loss at step 37800 : 17.872859954833984\n",
      "Loss at step 37900 : 12.488978385925293\n",
      "Loss at step 38000 : 14.666243553161621\n",
      "Loss at step 38100 : 16.34489631652832\n",
      "Loss at step 38200 : 14.214056968688965\n",
      "Loss at step 38300 : 13.651144981384277\n",
      "Loss at step 38400 : 11.319488525390625\n",
      "Loss at step 38500 : 11.527355194091797\n",
      "Loss at step 38600 : 15.340350151062012\n",
      "Loss at step 38700 : 14.161386489868164\n",
      "Loss at step 38800 : 12.52608585357666\n",
      "Loss at step 38900 : 15.317755699157715\n",
      "Loss at step 39000 : 16.037561416625977\n",
      "Loss at step 39100 : 19.636741638183594\n",
      "Loss at step 39200 : 15.312358856201172\n",
      "Loss at step 39300 : 14.248435020446777\n",
      "Loss at step 39400 : 17.667455673217773\n",
      "Loss at step 39500 : 15.650250434875488\n",
      "Loss at step 39600 : 20.196941375732422\n",
      "Loss at step 39700 : 15.384191513061523\n",
      "Loss at step 39800 : 12.678434371948242\n",
      "Loss at step 39900 : 12.293750762939453\n",
      "Loss at step 40000 : 17.479307174682617\n",
      "Nearest to love: like, in, a, are, the,\n",
      "Nearest to hate: thick, static, descends, remarkable, crossroads,\n",
      "Nearest to happy: proportions, bumper, in, on, content,\n",
      "Nearest to sad: gives, adolescent, us, masterful, end,\n",
      "Nearest to man: are, enough, of, touching, very,\n",
      "Nearest to woman: art, what, scathing, steers, special,\n",
      "Model saved in file: C:\\Users\\Evan\\Documents\\TensorflowExamples\\temp\\doc2vec_movie_embeddings.ckpt\n",
      "Loss at step 40100 : 18.856582641601562\n",
      "Loss at step 40200 : 14.044904708862305\n",
      "Loss at step 40300 : 17.953475952148438\n",
      "Loss at step 40400 : 15.074601173400879\n",
      "Loss at step 40500 : 12.596879005432129\n",
      "Loss at step 40600 : 16.203052520751953\n",
      "Loss at step 40700 : 16.03180503845215\n",
      "Loss at step 40800 : 16.849519729614258\n",
      "Loss at step 40900 : 16.450143814086914\n",
      "Loss at step 41000 : 12.6151704788208\n",
      "Loss at step 41100 : 14.777756690979004\n",
      "Loss at step 41200 : 12.478853225708008\n",
      "Loss at step 41300 : 15.378279685974121\n",
      "Loss at step 41400 : 12.769915580749512\n",
      "Loss at step 41500 : 14.574935913085938\n",
      "Loss at step 41600 : 22.360456466674805\n",
      "Loss at step 41700 : 23.634862899780273\n",
      "Loss at step 41800 : 13.726147651672363\n",
      "Loss at step 41900 : 13.618252754211426\n",
      "Loss at step 42000 : 13.247649192810059\n",
      "Loss at step 42100 : 16.34587860107422\n",
      "Loss at step 42200 : 14.952548027038574\n",
      "Loss at step 42300 : 15.651933670043945\n",
      "Loss at step 42400 : 12.184525489807129\n",
      "Loss at step 42500 : 12.981900215148926\n",
      "Loss at step 42600 : 14.022658348083496\n",
      "Loss at step 42700 : 14.601351737976074\n",
      "Loss at step 42800 : 17.70420265197754\n",
      "Loss at step 42900 : 17.388168334960938\n",
      "Loss at step 43000 : 13.52639102935791\n",
      "Loss at step 43100 : 18.562606811523438\n",
      "Loss at step 43200 : 16.082576751708984\n",
      "Loss at step 43300 : 10.986753463745117\n",
      "Loss at step 43400 : 15.218657493591309\n",
      "Loss at step 43500 : 17.327407836914062\n",
      "Loss at step 43600 : 14.197806358337402\n",
      "Loss at step 43700 : 13.4674654006958\n",
      "Loss at step 43800 : 21.245885848999023\n",
      "Loss at step 43900 : 14.175387382507324\n",
      "Loss at step 44000 : 14.290165901184082\n",
      "Loss at step 44100 : 13.583494186401367\n",
      "Loss at step 44200 : 12.815875053405762\n",
      "Loss at step 44300 : 15.907737731933594\n",
      "Loss at step 44400 : 17.73272132873535\n",
      "Loss at step 44500 : 13.075712203979492\n",
      "Loss at step 44600 : 15.771862983703613\n",
      "Loss at step 44700 : 12.993012428283691\n",
      "Loss at step 44800 : 19.05209732055664\n",
      "Loss at step 44900 : 12.32575798034668\n",
      "Loss at step 45000 : 16.707292556762695\n",
      "Nearest to love: like, in, a, are, the,\n",
      "Nearest to hate: thick, static, descends, remarkable, crossroads,\n",
      "Nearest to happy: proportions, bumper, in, on, content,\n",
      "Nearest to sad: gives, adolescent, us, masterful, end,\n",
      "Nearest to man: are, enough, of, very, touching,\n",
      "Nearest to woman: art, what, scathing, steers, special,\n",
      "Model saved in file: C:\\Users\\Evan\\Documents\\TensorflowExamples\\temp\\doc2vec_movie_embeddings.ckpt\n",
      "Loss at step 45100 : 14.702680587768555\n",
      "Loss at step 45200 : 17.700475692749023\n",
      "Loss at step 45300 : 16.882234573364258\n",
      "Loss at step 45400 : 19.54207420349121\n",
      "Loss at step 45500 : 13.807488441467285\n",
      "Loss at step 45600 : 13.620780944824219\n",
      "Loss at step 45700 : 14.281754493713379\n",
      "Loss at step 45800 : 11.802419662475586\n",
      "Loss at step 45900 : 16.89442253112793\n",
      "Loss at step 46000 : 15.165287017822266\n",
      "Loss at step 46100 : 11.684078216552734\n",
      "Loss at step 46200 : 13.329052925109863\n",
      "Loss at step 46300 : 13.098396301269531\n",
      "Loss at step 46400 : 14.288978576660156\n",
      "Loss at step 46500 : 17.835678100585938\n",
      "Loss at step 46600 : 11.214978218078613\n",
      "Loss at step 46700 : 12.43496322631836\n",
      "Loss at step 46800 : 12.041970252990723\n",
      "Loss at step 46900 : 16.070560455322266\n",
      "Loss at step 47000 : 12.265791893005371\n",
      "Loss at step 47100 : 17.79690170288086\n",
      "Loss at step 47200 : 13.508539199829102\n",
      "Loss at step 47300 : 18.84852409362793\n",
      "Loss at step 47400 : 17.736608505249023\n",
      "Loss at step 47500 : 13.94199275970459\n",
      "Loss at step 47600 : 15.091919898986816\n",
      "Loss at step 47700 : 12.675315856933594\n",
      "Loss at step 47800 : 13.43843936920166\n",
      "Loss at step 47900 : 16.394620895385742\n",
      "Loss at step 48000 : 11.73038101196289\n",
      "Loss at step 48100 : 16.31987190246582\n",
      "Loss at step 48200 : 15.426861763000488\n",
      "Loss at step 48300 : 17.757545471191406\n",
      "Loss at step 48400 : 15.174347877502441\n",
      "Loss at step 48500 : 17.215930938720703\n",
      "Loss at step 48600 : 13.256603240966797\n",
      "Loss at step 48700 : 13.029589653015137\n",
      "Loss at step 48800 : 12.243804931640625\n",
      "Loss at step 48900 : 15.505594253540039\n",
      "Loss at step 49000 : 15.499756813049316\n",
      "Loss at step 49100 : 11.51128101348877\n",
      "Loss at step 49200 : 17.222457885742188\n",
      "Loss at step 49300 : 12.45167350769043\n",
      "Loss at step 49400 : 15.476836204528809\n",
      "Loss at step 49500 : 15.293503761291504\n",
      "Loss at step 49600 : 20.3625545501709\n",
      "Loss at step 49700 : 16.14179039001465\n",
      "Loss at step 49800 : 12.718134880065918\n",
      "Loss at step 49900 : 16.405803680419922\n",
      "Loss at step 50000 : 17.805349349975586\n",
      "Nearest to love: like, in, a, are, the,\n",
      "Nearest to hate: thick, static, descends, remarkable, crossroads,\n",
      "Nearest to happy: proportions, bumper, in, on, content,\n",
      "Nearest to sad: gives, adolescent, us, masterful, end,\n",
      "Nearest to man: are, enough, of, very, touching,\n",
      "Nearest to woman: art, what, scathing, steers, special,\n",
      "Model saved in file: C:\\Users\\Evan\\Documents\\TensorflowExamples\\temp\\doc2vec_movie_embeddings.ckpt\n",
      "Loss at step 50100 : 18.547710418701172\n",
      "Loss at step 50200 : 13.374914169311523\n",
      "Loss at step 50300 : 15.978765487670898\n",
      "Loss at step 50400 : 15.625493049621582\n",
      "Loss at step 50500 : 15.190141677856445\n",
      "Loss at step 50600 : 15.377937316894531\n",
      "Loss at step 50700 : 14.63831901550293\n",
      "Loss at step 50800 : 19.135902404785156\n",
      "Loss at step 50900 : 14.786001205444336\n",
      "Loss at step 51000 : 15.56961727142334\n",
      "Loss at step 51100 : 10.469944953918457\n",
      "Loss at step 51200 : 12.840832710266113\n",
      "Loss at step 51300 : 13.738150596618652\n",
      "Loss at step 51400 : 13.20248031616211\n",
      "Loss at step 51500 : 14.662596702575684\n",
      "Loss at step 51600 : 19.9583797454834\n",
      "Loss at step 51700 : 14.558120727539062\n",
      "Loss at step 51800 : 13.469605445861816\n",
      "Loss at step 51900 : 16.03708267211914\n",
      "Loss at step 52000 : 15.92485523223877\n",
      "Loss at step 52100 : 14.796941757202148\n",
      "Loss at step 52200 : 12.886954307556152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 52300 : 11.252276420593262\n",
      "Loss at step 52400 : 11.752406120300293\n",
      "Loss at step 52500 : 20.518871307373047\n",
      "Loss at step 52600 : 19.557241439819336\n",
      "Loss at step 52700 : 12.959529876708984\n",
      "Loss at step 52800 : 15.395519256591797\n",
      "Loss at step 52900 : 17.045181274414062\n",
      "Loss at step 53000 : 13.79113483428955\n",
      "Loss at step 53100 : 16.898427963256836\n",
      "Loss at step 53200 : 12.566767692565918\n",
      "Loss at step 53300 : 17.570972442626953\n",
      "Loss at step 53400 : 10.656020164489746\n",
      "Loss at step 53500 : 11.923474311828613\n",
      "Loss at step 53600 : 15.66443920135498\n",
      "Loss at step 53700 : 13.12232780456543\n",
      "Loss at step 53800 : 16.689939498901367\n",
      "Loss at step 53900 : 18.426223754882812\n",
      "Loss at step 54000 : 15.300277709960938\n",
      "Loss at step 54100 : 10.216903686523438\n",
      "Loss at step 54200 : 13.025334358215332\n",
      "Loss at step 54300 : 13.845613479614258\n",
      "Loss at step 54400 : 15.691981315612793\n",
      "Loss at step 54500 : 13.744384765625\n",
      "Loss at step 54600 : 14.357818603515625\n",
      "Loss at step 54700 : 14.537343978881836\n",
      "Loss at step 54800 : 12.361062049865723\n",
      "Loss at step 54900 : 16.47039031982422\n",
      "Loss at step 55000 : 16.64091682434082\n",
      "Nearest to love: like, in, a, are, the,\n",
      "Nearest to hate: thick, static, descends, remarkable, crossroads,\n",
      "Nearest to happy: proportions, bumper, in, on, content,\n",
      "Nearest to sad: gives, adolescent, us, masterful, end,\n",
      "Nearest to man: are, enough, of, very, never,\n",
      "Nearest to woman: art, what, scathing, steers, special,\n",
      "Model saved in file: C:\\Users\\Evan\\Documents\\TensorflowExamples\\temp\\doc2vec_movie_embeddings.ckpt\n",
      "Loss at step 55100 : 13.031607627868652\n",
      "Loss at step 55200 : 16.9606876373291\n",
      "Loss at step 55300 : 14.699403762817383\n",
      "Loss at step 55400 : 15.600083351135254\n",
      "Loss at step 55500 : 13.744565963745117\n",
      "Loss at step 55600 : 13.098443031311035\n",
      "Loss at step 55700 : 16.51552963256836\n",
      "Loss at step 55800 : 16.531600952148438\n",
      "Loss at step 55900 : 18.306825637817383\n",
      "Loss at step 56000 : 13.250738143920898\n",
      "Loss at step 56100 : 15.662409782409668\n",
      "Loss at step 56200 : 15.613669395446777\n",
      "Loss at step 56300 : 13.53339672088623\n",
      "Loss at step 56400 : 13.483344078063965\n",
      "Loss at step 56500 : 17.756765365600586\n",
      "Loss at step 56600 : 16.419376373291016\n",
      "Loss at step 56700 : 14.97465991973877\n",
      "Loss at step 56800 : 12.872329711914062\n",
      "Loss at step 56900 : 13.684353828430176\n",
      "Loss at step 57000 : 14.613009452819824\n",
      "Loss at step 57100 : 14.03211498260498\n",
      "Loss at step 57200 : 14.727105140686035\n",
      "Loss at step 57300 : 15.022099494934082\n",
      "Loss at step 57400 : 15.43978500366211\n",
      "Loss at step 57500 : 10.819119453430176\n",
      "Loss at step 57600 : 15.726195335388184\n",
      "Loss at step 57700 : 18.998374938964844\n"
     ]
    }
   ],
   "source": [
    "# Run the doc2vec model.\n",
    "print('Starting Training')\n",
    "loss_vec = []\n",
    "loss_x_vec = []\n",
    "for i in range(generations):\n",
    "    batch_inputs, batch_labels = text_helpers.generate_batch_data(text_data, batch_size,\n",
    "                                                                  window_size, method='doc2vec')\n",
    "    feed_dict = {x_inputs : batch_inputs, y_target : batch_labels}\n",
    "\n",
    "    # Run the train step\n",
    "    sess.run(train_step, feed_dict=feed_dict)\n",
    "\n",
    "    # Return the loss\n",
    "    if (i+1) % print_loss_every == 0:\n",
    "        loss_val = sess.run(loss, feed_dict=feed_dict)\n",
    "        loss_vec.append(loss_val)\n",
    "        loss_x_vec.append(i+1)\n",
    "        print('Loss at step {} : {}'.format(i+1, loss_val))\n",
    "      \n",
    "    # Validation: Print some random words and top 5 related words\n",
    "    if (i+1) % print_valid_every == 0:\n",
    "        sim = sess.run(similarity, feed_dict=feed_dict)\n",
    "        for j in range(len(valid_words)):\n",
    "            valid_word = word_dictionary_rev[valid_examples[j]]\n",
    "            top_k = 5 # number of nearest neighbors\n",
    "            nearest = (-sim[j, :]).argsort()[1:top_k+1]\n",
    "            log_str = \"Nearest to {}:\".format(valid_word)\n",
    "            for k in range(top_k):\n",
    "                close_word = word_dictionary_rev[nearest[k]]\n",
    "                log_str = '{} {},'.format(log_str, close_word)\n",
    "            print(log_str)\n",
    "            \n",
    "    # Save dictionary + embeddings\n",
    "    if (i+1) % save_embeddings_every == 0:\n",
    "        # Save vocabulary dictionary\n",
    "        with open(os.path.join(data_folder_name,'movie_vocab.pkl'), 'wb') as f:\n",
    "            pickle.dump(word_dictionary, f)\n",
    "        \n",
    "        # Save embeddings\n",
    "        model_checkpoint_path = os.path.join(os.getcwd(),data_folder_name,'doc2vec_movie_embeddings.ckpt')\n",
    "        save_path = saver.save(sess, model_checkpoint_path)\n",
    "        print('Model saved in file: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 20\n",
    "logistic_batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to keep the indices sorted to keep track of document index\n",
    "train_indices = np.sort(np.random.choice(len(target), round(0.8*len(target)), replace=False))\n",
    "test_indices = np.sort(np.array(list(set(range(len(target))) - set(train_indices))))\n",
    "texts_train = [x for ix, x in enumerate(texts) if ix in train_indices]\n",
    "texts_test = [x for ix, x in enumerate(texts) if ix in test_indices]\n",
    "target_train = np.array([x for ix, x in enumerate(target) if ix in train_indices])\n",
    "target_test = np.array([x for ix, x in enumerate(target) if ix in test_indices])\n",
    "\n",
    "# Convert texts to lists of indices\n",
    "text_data_train = np.array(text_helpers.text_to_numbers(texts_train, word_dictionary))\n",
    "text_data_test = np.array(text_helpers.text_to_numbers(texts_test, word_dictionary))\n",
    "\n",
    "# Pad/crop movie reviews to specific length\n",
    "text_data_train = np.array([x[0:max_words] for x in [y+[0]*max_words for y in text_data_train]])\n",
    "text_data_test = np.array([x[0:max_words] for x in [y+[0]*max_words for y in text_data_test]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Logistic placeholders\n",
    "log_x_inputs = tf.placeholder(tf.int32, shape=[None, max_words + 1]) # plus 1 for doc index\n",
    "log_y_target = tf.placeholder(tf.int32, shape=[None, 1])\n",
    "\n",
    "# Define logistic embedding lookup (needed if we have two different batch sizes)\n",
    "# Add together element embeddings in window:\n",
    "log_embed = tf.zeros([logistic_batch_size, embedding_size])\n",
    "for element in range(max_words):\n",
    "    log_embed += tf.nn.embedding_lookup(embeddings, log_x_inputs[:, element])\n",
    "\n",
    "log_doc_indices = tf.slice(log_x_inputs, [0,max_words],[logistic_batch_size,1])\n",
    "log_doc_embed = tf.nn.embedding_lookup(doc_embeddings,log_doc_indices)\n",
    "\n",
    "# concatenate embeddings\n",
    "log_final_embed = tf.concat(axis=1, values=[log_embed, tf.squeeze(log_doc_embed)])\n",
    "\n",
    "# Define model:\n",
    "# Create variables for logistic regression\n",
    "A = tf.Variable(tf.random_normal(shape=[concatenated_size,1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "# Declare logistic model (sigmoid in loss function)\n",
    "model_output = tf.add(tf.matmul(log_final_embed, A), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare loss function (Cross Entropy loss)\n",
    "logistic_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output, labels=tf.cast(log_y_target, tf.float32)))\n",
    "\n",
    "# Actual Prediction\n",
    "prediction = tf.round(tf.sigmoid(model_output))\n",
    "predictions_correct = tf.cast(tf.equal(prediction, tf.cast(log_y_target, tf.float32)), tf.float32)\n",
    "accuracy = tf.reduce_mean(predictions_correct)\n",
    "\n",
    "# Declare optimizer\n",
    "logistic_opt = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "logistic_train_step = logistic_opt.minimize(logistic_loss, var_list=[A, b])\n",
    "\n",
    "# Intitialize Variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start Logistic Regression\n",
    "print('Starting Logistic Doc2Vec Model Training')\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "i_data = []\n",
    "for i in range(10000):\n",
    "    rand_index = np.random.choice(text_data_train.shape[0], size=logistic_batch_size)\n",
    "    rand_x = text_data_train[rand_index]\n",
    "    # Append review index at the end of text data\n",
    "    rand_x_doc_indices = train_indices[rand_index]\n",
    "    rand_x = np.hstack((rand_x, np.transpose([rand_x_doc_indices])))\n",
    "    rand_y = np.transpose([target_train[rand_index]])\n",
    "    \n",
    "    feed_dict = {log_x_inputs : rand_x, log_y_target : rand_y}\n",
    "    sess.run(logistic_train_step, feed_dict=feed_dict)\n",
    "    \n",
    "    # Only record loss and accuracy every 100 generations\n",
    "    if (i+1)%100==0:\n",
    "        rand_index_test = np.random.choice(text_data_test.shape[0], size=logistic_batch_size)\n",
    "        rand_x_test = text_data_test[rand_index_test]\n",
    "        # Append review index at the end of text data\n",
    "        rand_x_doc_indices_test = test_indices[rand_index_test]\n",
    "        rand_x_test = np.hstack((rand_x_test, np.transpose([rand_x_doc_indices_test])))\n",
    "        rand_y_test = np.transpose([target_test[rand_index_test]])\n",
    "        \n",
    "        test_feed_dict = {log_x_inputs: rand_x_test, log_y_target: rand_y_test}\n",
    "        \n",
    "        i_data.append(i+1)\n",
    "\n",
    "        train_loss_temp = sess.run(logistic_loss, feed_dict=feed_dict)\n",
    "        train_loss.append(train_loss_temp)\n",
    "        \n",
    "        test_loss_temp = sess.run(logistic_loss, feed_dict=test_feed_dict)\n",
    "        test_loss.append(test_loss_temp)\n",
    "        \n",
    "        train_acc_temp = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        train_acc.append(train_acc_temp)\n",
    "    \n",
    "        test_acc_temp = sess.run(accuracy, feed_dict=test_feed_dict)\n",
    "        test_acc.append(test_acc_temp)\n",
    "    if (i+1)%500==0:\n",
    "        acc_and_loss = [i+1, train_loss_temp, test_loss_temp, train_acc_temp, test_acc_temp]\n",
    "        acc_and_loss = [np.round(x,2) for x in acc_and_loss]\n",
    "        print('Generation # {}. Train Loss (Test Loss): {:.2f} ({:.2f}). Train Acc (Test Acc): {:.2f} ({:.2f})'.format(*acc_and_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot loss over time\n",
    "plt.plot(i_data, train_loss, 'k-', label='Train Loss')\n",
    "plt.plot(i_data, test_loss, 'r--', label='Test Loss', linewidth=4)\n",
    "plt.title('Cross Entropy Loss per Generation')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Plot train and test accuracy\n",
    "plt.plot(i_data, train_acc, 'k-', label='Train Set Accuracy')\n",
    "plt.plot(i_data, test_acc, 'r--', label='Test Set Accuracy', linewidth=4)\n",
    "plt.title('Train and Test Accuracy')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
