{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1280, Minibatch Loss= 0.707406, Training Accuracy= 0.49219\n",
      "Iter 2560, Minibatch Loss= 0.687201, Training Accuracy= 0.48438\n",
      "Iter 3840, Minibatch Loss= 0.681996, Training Accuracy= 0.49219\n",
      "Iter 5120, Minibatch Loss= 0.694412, Training Accuracy= 0.56731\n",
      "Iter 6400, Minibatch Loss= 0.697460, Training Accuracy= 0.54688\n",
      "Iter 7680, Minibatch Loss= 0.682088, Training Accuracy= 0.53906\n",
      "Iter 8960, Minibatch Loss= 0.685347, Training Accuracy= 0.50781\n",
      "Iter 10240, Minibatch Loss= 0.691793, Training Accuracy= 0.55769\n",
      "Iter 11520, Minibatch Loss= 0.694166, Training Accuracy= 0.50000\n",
      "Iter 12800, Minibatch Loss= 0.680307, Training Accuracy= 0.59375\n",
      "Iter 14080, Minibatch Loss= 0.686946, Training Accuracy= 0.54688\n",
      "Iter 15360, Minibatch Loss= 0.690448, Training Accuracy= 0.58654\n",
      "Iter 16640, Minibatch Loss= 0.692622, Training Accuracy= 0.51562\n",
      "Iter 17920, Minibatch Loss= 0.679287, Training Accuracy= 0.59375\n",
      "Iter 19200, Minibatch Loss= 0.687464, Training Accuracy= 0.54688\n",
      "Iter 20480, Minibatch Loss= 0.689352, Training Accuracy= 0.61538\n",
      "Iter 21760, Minibatch Loss= 0.691586, Training Accuracy= 0.53906\n",
      "Iter 23040, Minibatch Loss= 0.678460, Training Accuracy= 0.59375\n",
      "Iter 24320, Minibatch Loss= 0.687447, Training Accuracy= 0.53125\n",
      "Iter 25600, Minibatch Loss= 0.688285, Training Accuracy= 0.61538\n",
      "Iter 26880, Minibatch Loss= 0.690690, Training Accuracy= 0.53906\n",
      "Iter 28160, Minibatch Loss= 0.677673, Training Accuracy= 0.57031\n",
      "Iter 29440, Minibatch Loss= 0.687172, Training Accuracy= 0.53125\n",
      "Iter 30720, Minibatch Loss= 0.687188, Training Accuracy= 0.60577\n",
      "Iter 32000, Minibatch Loss= 0.689804, Training Accuracy= 0.54688\n",
      "Iter 33280, Minibatch Loss= 0.676872, Training Accuracy= 0.57812\n",
      "Iter 34560, Minibatch Loss= 0.686764, Training Accuracy= 0.53125\n",
      "Iter 35840, Minibatch Loss= 0.686033, Training Accuracy= 0.60577\n",
      "Iter 37120, Minibatch Loss= 0.688872, Training Accuracy= 0.53906\n",
      "Iter 38400, Minibatch Loss= 0.676029, Training Accuracy= 0.57812\n",
      "Iter 39680, Minibatch Loss= 0.686276, Training Accuracy= 0.53125\n",
      "Iter 40960, Minibatch Loss= 0.684800, Training Accuracy= 0.60577\n",
      "Iter 42240, Minibatch Loss= 0.687866, Training Accuracy= 0.54688\n",
      "Iter 43520, Minibatch Loss= 0.675124, Training Accuracy= 0.57812\n",
      "Iter 44800, Minibatch Loss= 0.685724, Training Accuracy= 0.53906\n",
      "Iter 46080, Minibatch Loss= 0.683472, Training Accuracy= 0.60577\n",
      "Iter 47360, Minibatch Loss= 0.686768, Training Accuracy= 0.55469\n",
      "Iter 48640, Minibatch Loss= 0.674141, Training Accuracy= 0.57812\n",
      "Iter 49920, Minibatch Loss= 0.685112, Training Accuracy= 0.54688\n",
      "Iter 51200, Minibatch Loss= 0.682029, Training Accuracy= 0.60577\n",
      "Iter 52480, Minibatch Loss= 0.685558, Training Accuracy= 0.56250\n",
      "Iter 53760, Minibatch Loss= 0.673063, Training Accuracy= 0.58594\n",
      "Iter 55040, Minibatch Loss= 0.684434, Training Accuracy= 0.55469\n",
      "Iter 56320, Minibatch Loss= 0.680449, Training Accuracy= 0.60577\n",
      "Iter 57600, Minibatch Loss= 0.684217, Training Accuracy= 0.56250\n",
      "Iter 58880, Minibatch Loss= 0.671872, Training Accuracy= 0.57812\n",
      "Iter 60160, Minibatch Loss= 0.683680, Training Accuracy= 0.56250\n",
      "Iter 61440, Minibatch Loss= 0.678708, Training Accuracy= 0.60577\n",
      "Iter 62720, Minibatch Loss= 0.682722, Training Accuracy= 0.56250\n",
      "Iter 64000, Minibatch Loss= 0.670545, Training Accuracy= 0.57812\n",
      "Iter 65280, Minibatch Loss= 0.682837, Training Accuracy= 0.57031\n",
      "Iter 66560, Minibatch Loss= 0.676776, Training Accuracy= 0.60577\n",
      "Iter 67840, Minibatch Loss= 0.681046, Training Accuracy= 0.59375\n",
      "Iter 69120, Minibatch Loss= 0.669061, Training Accuracy= 0.58594\n",
      "Iter 70400, Minibatch Loss= 0.681887, Training Accuracy= 0.58594\n",
      "Iter 71680, Minibatch Loss= 0.674619, Training Accuracy= 0.61538\n",
      "Iter 72960, Minibatch Loss= 0.679155, Training Accuracy= 0.60156\n",
      "Iter 74240, Minibatch Loss= 0.667389, Training Accuracy= 0.58594\n",
      "Iter 75520, Minibatch Loss= 0.680812, Training Accuracy= 0.58594\n",
      "Iter 76800, Minibatch Loss= 0.672195, Training Accuracy= 0.62500\n",
      "Iter 78080, Minibatch Loss= 0.677011, Training Accuracy= 0.59375\n",
      "Iter 79360, Minibatch Loss= 0.665495, Training Accuracy= 0.59375\n",
      "Iter 80640, Minibatch Loss= 0.679585, Training Accuracy= 0.58594\n",
      "Iter 81920, Minibatch Loss= 0.669452, Training Accuracy= 0.63462\n",
      "Iter 83200, Minibatch Loss= 0.674567, Training Accuracy= 0.58594\n",
      "Iter 84480, Minibatch Loss= 0.663339, Training Accuracy= 0.59375\n",
      "Iter 85760, Minibatch Loss= 0.678177, Training Accuracy= 0.57812\n",
      "Iter 87040, Minibatch Loss= 0.666329, Training Accuracy= 0.63462\n",
      "Iter 88320, Minibatch Loss= 0.671764, Training Accuracy= 0.60938\n",
      "Iter 89600, Minibatch Loss= 0.660870, Training Accuracy= 0.60156\n",
      "Iter 90880, Minibatch Loss= 0.676549, Training Accuracy= 0.59375\n",
      "Iter 92160, Minibatch Loss= 0.662751, Training Accuracy= 0.64423\n",
      "Iter 93440, Minibatch Loss= 0.668532, Training Accuracy= 0.60156\n",
      "Iter 94720, Minibatch Loss= 0.658027, Training Accuracy= 0.60156\n",
      "Iter 96000, Minibatch Loss= 0.674655, Training Accuracy= 0.63281\n",
      "Iter 97280, Minibatch Loss= 0.658624, Training Accuracy= 0.63462\n",
      "Iter 98560, Minibatch Loss= 0.664785, Training Accuracy= 0.62500\n",
      "Iter 99840, Minibatch Loss= 0.654738, Training Accuracy= 0.60938\n",
      "Iter 101120, Minibatch Loss= 0.672434, Training Accuracy= 0.62500\n",
      "Iter 102400, Minibatch Loss= 0.653834, Training Accuracy= 0.64423\n",
      "Iter 103680, Minibatch Loss= 0.660418, Training Accuracy= 0.63281\n",
      "Iter 104960, Minibatch Loss= 0.650914, Training Accuracy= 0.60938\n",
      "Iter 106240, Minibatch Loss= 0.669809, Training Accuracy= 0.62500\n",
      "Iter 107520, Minibatch Loss= 0.648243, Training Accuracy= 0.64423\n",
      "Iter 108800, Minibatch Loss= 0.655303, Training Accuracy= 0.62500\n",
      "Iter 110080, Minibatch Loss= 0.646453, Training Accuracy= 0.62500\n",
      "Iter 111360, Minibatch Loss= 0.666684, Training Accuracy= 0.63281\n",
      "Iter 112640, Minibatch Loss= 0.641691, Training Accuracy= 0.64423\n",
      "Iter 113920, Minibatch Loss= 0.649292, Training Accuracy= 0.63281\n",
      "Iter 115200, Minibatch Loss= 0.641244, Training Accuracy= 0.64062\n",
      "Iter 116480, Minibatch Loss= 0.662935, Training Accuracy= 0.64062\n",
      "Iter 117760, Minibatch Loss= 0.633995, Training Accuracy= 0.65385\n",
      "Iter 119040, Minibatch Loss= 0.642216, Training Accuracy= 0.64062\n",
      "Iter 120320, Minibatch Loss= 0.635180, Training Accuracy= 0.64062\n",
      "Iter 121600, Minibatch Loss= 0.658416, Training Accuracy= 0.64062\n",
      "Iter 122880, Minibatch Loss= 0.624975, Training Accuracy= 0.66346\n",
      "Iter 124160, Minibatch Loss= 0.633909, Training Accuracy= 0.64062\n",
      "Iter 125440, Minibatch Loss= 0.628186, Training Accuracy= 0.60938\n",
      "Iter 126720, Minibatch Loss= 0.652962, Training Accuracy= 0.64062\n",
      "Iter 128000, Minibatch Loss= 0.614475, Training Accuracy= 0.66346\n",
      "Iter 129280, Minibatch Loss= 0.624238, Training Accuracy= 0.64062\n",
      "Iter 130560, Minibatch Loss= 0.620259, Training Accuracy= 0.61719\n",
      "Iter 131840, Minibatch Loss= 0.646416, Training Accuracy= 0.64844\n",
      "Iter 133120, Minibatch Loss= 0.602416, Training Accuracy= 0.67308\n",
      "Iter 134400, Minibatch Loss= 0.613152, Training Accuracy= 0.64844\n",
      "Iter 135680, Minibatch Loss= 0.611524, Training Accuracy= 0.61719\n",
      "Iter 136960, Minibatch Loss= 0.638668, Training Accuracy= 0.69531\n",
      "Iter 138240, Minibatch Loss= 0.588849, Training Accuracy= 0.69231\n",
      "Iter 139520, Minibatch Loss= 0.600726, Training Accuracy= 0.64844\n",
      "Iter 140800, Minibatch Loss= 0.602251, Training Accuracy= 0.63281\n",
      "Iter 142080, Minibatch Loss= 0.629695, Training Accuracy= 0.70312\n",
      "Iter 143360, Minibatch Loss= 0.573988, Training Accuracy= 0.69231\n",
      "Iter 144640, Minibatch Loss= 0.587177, Training Accuracy= 0.69531\n",
      "Iter 145920, Minibatch Loss= 0.592809, Training Accuracy= 0.62500\n",
      "Iter 147200, Minibatch Loss= 0.619592, Training Accuracy= 0.68750\n",
      "Iter 148480, Minibatch Loss= 0.558234, Training Accuracy= 0.71154\n",
      "Iter 149760, Minibatch Loss= 0.572826, Training Accuracy= 0.71875\n",
      "Iter 151040, Minibatch Loss= 0.583548, Training Accuracy= 0.64844\n",
      "Iter 152320, Minibatch Loss= 0.608568, Training Accuracy= 0.71094\n",
      "Iter 153600, Minibatch Loss= 0.542186, Training Accuracy= 0.72115\n",
      "Iter 154880, Minibatch Loss= 0.558101, Training Accuracy= 0.75000\n",
      "Iter 156160, Minibatch Loss= 0.574699, Training Accuracy= 0.62500\n",
      "Iter 157440, Minibatch Loss= 0.596932, Training Accuracy= 0.70312\n",
      "Iter 158720, Minibatch Loss= 0.526628, Training Accuracy= 0.75000\n",
      "Iter 160000, Minibatch Loss= 0.543565, Training Accuracy= 0.75781\n",
      "Iter 161280, Minibatch Loss= 0.566393, Training Accuracy= 0.65625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 162560, Minibatch Loss= 0.585067, Training Accuracy= 0.71875\n",
      "Iter 163840, Minibatch Loss= 0.512428, Training Accuracy= 0.75962\n",
      "Iter 165120, Minibatch Loss= 0.529889, Training Accuracy= 0.75781\n",
      "Iter 166400, Minibatch Loss= 0.558748, Training Accuracy= 0.65625\n",
      "Iter 167680, Minibatch Loss= 0.573395, Training Accuracy= 0.72656\n",
      "Iter 168960, Minibatch Loss= 0.500318, Training Accuracy= 0.75000\n",
      "Iter 170240, Minibatch Loss= 0.517690, Training Accuracy= 0.77344\n",
      "Iter 171520, Minibatch Loss= 0.551897, Training Accuracy= 0.64062\n",
      "Iter 172800, Minibatch Loss= 0.562360, Training Accuracy= 0.71094\n",
      "Iter 174080, Minibatch Loss= 0.490633, Training Accuracy= 0.75000\n",
      "Iter 175360, Minibatch Loss= 0.507366, Training Accuracy= 0.78125\n",
      "Iter 176640, Minibatch Loss= 0.545925, Training Accuracy= 0.64062\n",
      "Iter 177920, Minibatch Loss= 0.552397, Training Accuracy= 0.70312\n",
      "Iter 179200, Minibatch Loss= 0.483211, Training Accuracy= 0.75000\n",
      "Iter 180480, Minibatch Loss= 0.499021, Training Accuracy= 0.78125\n",
      "Iter 181760, Minibatch Loss= 0.540848, Training Accuracy= 0.64844\n",
      "Iter 183040, Minibatch Loss= 0.543822, Training Accuracy= 0.71094\n",
      "Iter 184320, Minibatch Loss= 0.477562, Training Accuracy= 0.75000\n",
      "Iter 185600, Minibatch Loss= 0.492497, Training Accuracy= 0.78906\n",
      "Iter 186880, Minibatch Loss= 0.536621, Training Accuracy= 0.66406\n",
      "Iter 188160, Minibatch Loss= 0.536726, Training Accuracy= 0.71094\n",
      "Iter 189440, Minibatch Loss= 0.473163, Training Accuracy= 0.75962\n",
      "Iter 190720, Minibatch Loss= 0.487465, Training Accuracy= 0.78906\n",
      "Iter 192000, Minibatch Loss= 0.533148, Training Accuracy= 0.70312\n",
      "Iter 193280, Minibatch Loss= 0.530975, Training Accuracy= 0.72656\n",
      "Iter 194560, Minibatch Loss= 0.469613, Training Accuracy= 0.77885\n",
      "Iter 195840, Minibatch Loss= 0.483541, Training Accuracy= 0.78125\n",
      "Iter 197120, Minibatch Loss= 0.530297, Training Accuracy= 0.71875\n",
      "Iter 198400, Minibatch Loss= 0.526318, Training Accuracy= 0.72656\n",
      "Iter 199680, Minibatch Loss= 0.466640, Training Accuracy= 0.80769\n",
      "Iter 200960, Minibatch Loss= 0.480373, Training Accuracy= 0.78906\n",
      "Iter 202240, Minibatch Loss= 0.527927, Training Accuracy= 0.71094\n",
      "Iter 203520, Minibatch Loss= 0.522489, Training Accuracy= 0.72656\n",
      "Iter 204800, Minibatch Loss= 0.464066, Training Accuracy= 0.80769\n",
      "Iter 206080, Minibatch Loss= 0.477690, Training Accuracy= 0.78906\n",
      "Iter 207360, Minibatch Loss= 0.525911, Training Accuracy= 0.71094\n",
      "Iter 208640, Minibatch Loss= 0.519269, Training Accuracy= 0.72656\n",
      "Iter 209920, Minibatch Loss= 0.461766, Training Accuracy= 0.80769\n",
      "Iter 211200, Minibatch Loss= 0.475311, Training Accuracy= 0.78906\n",
      "Iter 212480, Minibatch Loss= 0.524149, Training Accuracy= 0.71094\n",
      "Iter 213760, Minibatch Loss= 0.516490, Training Accuracy= 0.71875\n",
      "Iter 215040, Minibatch Loss= 0.459655, Training Accuracy= 0.80769\n",
      "Iter 216320, Minibatch Loss= 0.473126, Training Accuracy= 0.78125\n",
      "Iter 217600, Minibatch Loss= 0.522570, Training Accuracy= 0.70312\n",
      "Iter 218880, Minibatch Loss= 0.514035, Training Accuracy= 0.72656\n",
      "Iter 220160, Minibatch Loss= 0.457680, Training Accuracy= 0.81731\n",
      "Iter 221440, Minibatch Loss= 0.471073, Training Accuracy= 0.78125\n",
      "Iter 222720, Minibatch Loss= 0.521125, Training Accuracy= 0.69531\n",
      "Iter 224000, Minibatch Loss= 0.511823, Training Accuracy= 0.72656\n",
      "Iter 225280, Minibatch Loss= 0.455805, Training Accuracy= 0.81731\n",
      "Iter 226560, Minibatch Loss= 0.469118, Training Accuracy= 0.78125\n",
      "Iter 227840, Minibatch Loss= 0.519784, Training Accuracy= 0.71094\n",
      "Iter 229120, Minibatch Loss= 0.509798, Training Accuracy= 0.72656\n",
      "Iter 230400, Minibatch Loss= 0.454009, Training Accuracy= 0.81731\n",
      "Iter 231680, Minibatch Loss= 0.467244, Training Accuracy= 0.78906\n",
      "Iter 232960, Minibatch Loss= 0.518525, Training Accuracy= 0.71094\n",
      "Iter 234240, Minibatch Loss= 0.507920, Training Accuracy= 0.73438\n",
      "Iter 235520, Minibatch Loss= 0.452280, Training Accuracy= 0.81731\n",
      "Iter 236800, Minibatch Loss= 0.465438, Training Accuracy= 0.79688\n",
      "Iter 238080, Minibatch Loss= 0.517333, Training Accuracy= 0.71094\n",
      "Iter 239360, Minibatch Loss= 0.506161, Training Accuracy= 0.74219\n",
      "Iter 240640, Minibatch Loss= 0.450606, Training Accuracy= 0.81731\n",
      "Iter 241920, Minibatch Loss= 0.463695, Training Accuracy= 0.80469\n",
      "Iter 243200, Minibatch Loss= 0.516197, Training Accuracy= 0.70312\n",
      "Iter 244480, Minibatch Loss= 0.504501, Training Accuracy= 0.75000\n",
      "Iter 245760, Minibatch Loss= 0.448981, Training Accuracy= 0.81731\n",
      "Iter 247040, Minibatch Loss= 0.462007, Training Accuracy= 0.80469\n",
      "Iter 248320, Minibatch Loss= 0.515110, Training Accuracy= 0.70312\n",
      "Iter 249600, Minibatch Loss= 0.502922, Training Accuracy= 0.75000\n",
      "Iter 250880, Minibatch Loss= 0.447401, Training Accuracy= 0.81731\n",
      "Iter 252160, Minibatch Loss= 0.460370, Training Accuracy= 0.80469\n",
      "Iter 253440, Minibatch Loss= 0.514066, Training Accuracy= 0.71094\n",
      "Iter 254720, Minibatch Loss= 0.501414, Training Accuracy= 0.75000\n",
      "Iter 256000, Minibatch Loss= 0.445858, Training Accuracy= 0.81731\n",
      "Iter 257280, Minibatch Loss= 0.458781, Training Accuracy= 0.80469\n",
      "Iter 258560, Minibatch Loss= 0.513058, Training Accuracy= 0.71875\n",
      "Iter 259840, Minibatch Loss= 0.499966, Training Accuracy= 0.75000\n",
      "Iter 261120, Minibatch Loss= 0.444351, Training Accuracy= 0.81731\n",
      "Iter 262400, Minibatch Loss= 0.457234, Training Accuracy= 0.80469\n",
      "Iter 263680, Minibatch Loss= 0.512082, Training Accuracy= 0.72656\n",
      "Iter 264960, Minibatch Loss= 0.498572, Training Accuracy= 0.75000\n",
      "Iter 266240, Minibatch Loss= 0.442874, Training Accuracy= 0.81731\n",
      "Iter 267520, Minibatch Loss= 0.455727, Training Accuracy= 0.80469\n",
      "Iter 268800, Minibatch Loss= 0.511134, Training Accuracy= 0.71875\n",
      "Iter 270080, Minibatch Loss= 0.497223, Training Accuracy= 0.75000\n",
      "Iter 271360, Minibatch Loss= 0.441423, Training Accuracy= 0.81731\n",
      "Iter 272640, Minibatch Loss= 0.454256, Training Accuracy= 0.80469\n",
      "Iter 273920, Minibatch Loss= 0.510211, Training Accuracy= 0.71094\n",
      "Iter 275200, Minibatch Loss= 0.495915, Training Accuracy= 0.75000\n",
      "Iter 276480, Minibatch Loss= 0.439995, Training Accuracy= 0.81731\n",
      "Iter 277760, Minibatch Loss= 0.452818, Training Accuracy= 0.80469\n",
      "Iter 279040, Minibatch Loss= 0.509308, Training Accuracy= 0.71094\n",
      "Iter 280320, Minibatch Loss= 0.494642, Training Accuracy= 0.75000\n",
      "Iter 281600, Minibatch Loss= 0.438588, Training Accuracy= 0.81731\n",
      "Iter 282880, Minibatch Loss= 0.451410, Training Accuracy= 0.80469\n",
      "Iter 284160, Minibatch Loss= 0.508424, Training Accuracy= 0.71875\n",
      "Iter 285440, Minibatch Loss= 0.493400, Training Accuracy= 0.75000\n",
      "Iter 286720, Minibatch Loss= 0.437198, Training Accuracy= 0.81731\n",
      "Iter 288000, Minibatch Loss= 0.450029, Training Accuracy= 0.80469\n",
      "Iter 289280, Minibatch Loss= 0.507555, Training Accuracy= 0.71875\n",
      "Iter 290560, Minibatch Loss= 0.492186, Training Accuracy= 0.75000\n",
      "Iter 291840, Minibatch Loss= 0.435821, Training Accuracy= 0.81731\n",
      "Iter 293120, Minibatch Loss= 0.448673, Training Accuracy= 0.82031\n",
      "Iter 294400, Minibatch Loss= 0.506699, Training Accuracy= 0.71875\n",
      "Iter 295680, Minibatch Loss= 0.490996, Training Accuracy= 0.75781\n",
      "Iter 296960, Minibatch Loss= 0.434456, Training Accuracy= 0.83654\n",
      "Iter 298240, Minibatch Loss= 0.447340, Training Accuracy= 0.82031\n",
      "Iter 299520, Minibatch Loss= 0.505854, Training Accuracy= 0.71875\n",
      "Iter 300800, Minibatch Loss= 0.489826, Training Accuracy= 0.75781\n",
      "Iter 302080, Minibatch Loss= 0.433100, Training Accuracy= 0.83654\n",
      "Iter 303360, Minibatch Loss= 0.446027, Training Accuracy= 0.82812\n",
      "Iter 304640, Minibatch Loss= 0.505017, Training Accuracy= 0.71875\n",
      "Iter 305920, Minibatch Loss= 0.488673, Training Accuracy= 0.75781\n",
      "Iter 307200, Minibatch Loss= 0.431750, Training Accuracy= 0.83654\n",
      "Iter 308480, Minibatch Loss= 0.444732, Training Accuracy= 0.82031\n",
      "Iter 309760, Minibatch Loss= 0.504186, Training Accuracy= 0.71094\n",
      "Iter 311040, Minibatch Loss= 0.487535, Training Accuracy= 0.75781\n",
      "Iter 312320, Minibatch Loss= 0.430405, Training Accuracy= 0.83654\n",
      "Iter 313600, Minibatch Loss= 0.443454, Training Accuracy= 0.82031\n",
      "Iter 314880, Minibatch Loss= 0.503359, Training Accuracy= 0.71094\n",
      "Iter 316160, Minibatch Loss= 0.486408, Training Accuracy= 0.75781\n",
      "Iter 317440, Minibatch Loss= 0.429062, Training Accuracy= 0.83654\n",
      "Iter 318720, Minibatch Loss= 0.442189, Training Accuracy= 0.82031\n",
      "Iter 320000, Minibatch Loss= 0.502535, Training Accuracy= 0.71875\n",
      "Iter 321280, Minibatch Loss= 0.485290, Training Accuracy= 0.75781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 322560, Minibatch Loss= 0.427719, Training Accuracy= 0.83654\n",
      "Iter 323840, Minibatch Loss= 0.440938, Training Accuracy= 0.82031\n",
      "Iter 325120, Minibatch Loss= 0.501711, Training Accuracy= 0.71875\n",
      "Iter 326400, Minibatch Loss= 0.484179, Training Accuracy= 0.75781\n",
      "Iter 327680, Minibatch Loss= 0.426374, Training Accuracy= 0.83654\n",
      "Iter 328960, Minibatch Loss= 0.439696, Training Accuracy= 0.82031\n",
      "Iter 330240, Minibatch Loss= 0.500885, Training Accuracy= 0.71875\n",
      "Iter 331520, Minibatch Loss= 0.483071, Training Accuracy= 0.75781\n",
      "Iter 332800, Minibatch Loss= 0.425026, Training Accuracy= 0.83654\n",
      "Iter 334080, Minibatch Loss= 0.438463, Training Accuracy= 0.81250\n",
      "Iter 335360, Minibatch Loss= 0.500056, Training Accuracy= 0.72656\n",
      "Iter 336640, Minibatch Loss= 0.481964, Training Accuracy= 0.76562\n",
      "Iter 337920, Minibatch Loss= 0.423671, Training Accuracy= 0.83654\n",
      "Iter 339200, Minibatch Loss= 0.437237, Training Accuracy= 0.81250\n",
      "Iter 340480, Minibatch Loss= 0.499222, Training Accuracy= 0.72656\n",
      "Iter 341760, Minibatch Loss= 0.480856, Training Accuracy= 0.76562\n",
      "Iter 343040, Minibatch Loss= 0.422310, Training Accuracy= 0.83654\n",
      "Iter 344320, Minibatch Loss= 0.436016, Training Accuracy= 0.81250\n",
      "Iter 345600, Minibatch Loss= 0.498380, Training Accuracy= 0.72656\n",
      "Iter 346880, Minibatch Loss= 0.479743, Training Accuracy= 0.76562\n",
      "Iter 348160, Minibatch Loss= 0.420939, Training Accuracy= 0.83654\n",
      "Iter 349440, Minibatch Loss= 0.434798, Training Accuracy= 0.81250\n",
      "Iter 350720, Minibatch Loss= 0.497530, Training Accuracy= 0.72656\n",
      "Iter 352000, Minibatch Loss= 0.478625, Training Accuracy= 0.76562\n",
      "Iter 353280, Minibatch Loss= 0.419557, Training Accuracy= 0.83654\n",
      "Iter 354560, Minibatch Loss= 0.433581, Training Accuracy= 0.81250\n",
      "Iter 355840, Minibatch Loss= 0.496668, Training Accuracy= 0.73438\n",
      "Iter 357120, Minibatch Loss= 0.477497, Training Accuracy= 0.76562\n",
      "Iter 358400, Minibatch Loss= 0.418161, Training Accuracy= 0.83654\n",
      "Iter 359680, Minibatch Loss= 0.432364, Training Accuracy= 0.81250\n",
      "Iter 360960, Minibatch Loss= 0.495792, Training Accuracy= 0.73438\n",
      "Iter 362240, Minibatch Loss= 0.476357, Training Accuracy= 0.76562\n",
      "Iter 363520, Minibatch Loss= 0.416751, Training Accuracy= 0.83654\n",
      "Iter 364800, Minibatch Loss= 0.431143, Training Accuracy= 0.80469\n",
      "Iter 366080, Minibatch Loss= 0.494901, Training Accuracy= 0.73438\n",
      "Iter 367360, Minibatch Loss= 0.475202, Training Accuracy= 0.76562\n",
      "Iter 368640, Minibatch Loss= 0.415324, Training Accuracy= 0.83654\n",
      "Iter 369920, Minibatch Loss= 0.429918, Training Accuracy= 0.80469\n",
      "Iter 371200, Minibatch Loss= 0.493991, Training Accuracy= 0.74219\n",
      "Iter 372480, Minibatch Loss= 0.474029, Training Accuracy= 0.76562\n",
      "Iter 373760, Minibatch Loss= 0.413877, Training Accuracy= 0.83654\n",
      "Iter 375040, Minibatch Loss= 0.428685, Training Accuracy= 0.80469\n",
      "Iter 376320, Minibatch Loss= 0.493061, Training Accuracy= 0.74219\n",
      "Iter 377600, Minibatch Loss= 0.472835, Training Accuracy= 0.76562\n",
      "Iter 378880, Minibatch Loss= 0.412409, Training Accuracy= 0.83654\n",
      "Iter 380160, Minibatch Loss= 0.427442, Training Accuracy= 0.80469\n",
      "Iter 381440, Minibatch Loss= 0.492108, Training Accuracy= 0.75000\n",
      "Iter 382720, Minibatch Loss= 0.471617, Training Accuracy= 0.77344\n",
      "Iter 384000, Minibatch Loss= 0.410917, Training Accuracy= 0.83654\n",
      "Iter 385280, Minibatch Loss= 0.426187, Training Accuracy= 0.80469\n",
      "Iter 386560, Minibatch Loss= 0.491128, Training Accuracy= 0.75000\n",
      "Iter 387840, Minibatch Loss= 0.470371, Training Accuracy= 0.77344\n",
      "Iter 389120, Minibatch Loss= 0.409398, Training Accuracy= 0.83654\n",
      "Iter 390400, Minibatch Loss= 0.424916, Training Accuracy= 0.81250\n",
      "Iter 391680, Minibatch Loss= 0.490118, Training Accuracy= 0.75000\n",
      "Iter 392960, Minibatch Loss= 0.469092, Training Accuracy= 0.77344\n",
      "Iter 394240, Minibatch Loss= 0.407850, Training Accuracy= 0.83654\n",
      "Iter 395520, Minibatch Loss= 0.423627, Training Accuracy= 0.81250\n",
      "Iter 396800, Minibatch Loss= 0.489075, Training Accuracy= 0.75000\n",
      "Iter 398080, Minibatch Loss= 0.467777, Training Accuracy= 0.77344\n",
      "Iter 399360, Minibatch Loss= 0.406269, Training Accuracy= 0.83654\n",
      "Iter 400640, Minibatch Loss= 0.422316, Training Accuracy= 0.81250\n",
      "Iter 401920, Minibatch Loss= 0.487994, Training Accuracy= 0.75000\n",
      "Iter 403200, Minibatch Loss= 0.466421, Training Accuracy= 0.78125\n",
      "Iter 404480, Minibatch Loss= 0.404653, Training Accuracy= 0.83654\n",
      "Iter 405760, Minibatch Loss= 0.420980, Training Accuracy= 0.81250\n",
      "Iter 407040, Minibatch Loss= 0.486873, Training Accuracy= 0.75000\n",
      "Iter 408320, Minibatch Loss= 0.465018, Training Accuracy= 0.78125\n",
      "Iter 409600, Minibatch Loss= 0.402997, Training Accuracy= 0.83654\n",
      "Iter 410880, Minibatch Loss= 0.419614, Training Accuracy= 0.81250\n",
      "Iter 412160, Minibatch Loss= 0.485705, Training Accuracy= 0.75000\n",
      "Iter 413440, Minibatch Loss= 0.463563, Training Accuracy= 0.78125\n",
      "Iter 414720, Minibatch Loss= 0.401298, Training Accuracy= 0.83654\n",
      "Iter 416000, Minibatch Loss= 0.418213, Training Accuracy= 0.81250\n",
      "Iter 417280, Minibatch Loss= 0.484486, Training Accuracy= 0.75000\n",
      "Iter 418560, Minibatch Loss= 0.462050, Training Accuracy= 0.78125\n",
      "Iter 419840, Minibatch Loss= 0.399551, Training Accuracy= 0.83654\n",
      "Iter 421120, Minibatch Loss= 0.416774, Training Accuracy= 0.81250\n",
      "Iter 422400, Minibatch Loss= 0.483210, Training Accuracy= 0.75000\n",
      "Iter 423680, Minibatch Loss= 0.460471, Training Accuracy= 0.78125\n",
      "Iter 424960, Minibatch Loss= 0.397751, Training Accuracy= 0.83654\n",
      "Iter 426240, Minibatch Loss= 0.415289, Training Accuracy= 0.81250\n",
      "Iter 427520, Minibatch Loss= 0.481871, Training Accuracy= 0.75000\n",
      "Iter 428800, Minibatch Loss= 0.458819, Training Accuracy= 0.78125\n",
      "Iter 430080, Minibatch Loss= 0.395894, Training Accuracy= 0.83654\n",
      "Iter 431360, Minibatch Loss= 0.413754, Training Accuracy= 0.81250\n",
      "Iter 432640, Minibatch Loss= 0.480461, Training Accuracy= 0.73438\n",
      "Iter 433920, Minibatch Loss= 0.457084, Training Accuracy= 0.78125\n",
      "Iter 435200, Minibatch Loss= 0.393972, Training Accuracy= 0.83654\n",
      "Iter 436480, Minibatch Loss= 0.412160, Training Accuracy= 0.81250\n",
      "Iter 437760, Minibatch Loss= 0.478973, Training Accuracy= 0.73438\n",
      "Iter 439040, Minibatch Loss= 0.455256, Training Accuracy= 0.78125\n",
      "Iter 440320, Minibatch Loss= 0.391980, Training Accuracy= 0.83654\n",
      "Iter 441600, Minibatch Loss= 0.410501, Training Accuracy= 0.82031\n",
      "Iter 442880, Minibatch Loss= 0.477399, Training Accuracy= 0.72656\n",
      "Iter 444160, Minibatch Loss= 0.453324, Training Accuracy= 0.78125\n",
      "Iter 445440, Minibatch Loss= 0.389910, Training Accuracy= 0.83654\n",
      "Iter 446720, Minibatch Loss= 0.408766, Training Accuracy= 0.82031\n",
      "Iter 448000, Minibatch Loss= 0.475727, Training Accuracy= 0.72656\n",
      "Iter 449280, Minibatch Loss= 0.451273, Training Accuracy= 0.78125\n",
      "Iter 450560, Minibatch Loss= 0.387754, Training Accuracy= 0.83654\n",
      "Iter 451840, Minibatch Loss= 0.406946, Training Accuracy= 0.82812\n",
      "Iter 453120, Minibatch Loss= 0.473948, Training Accuracy= 0.72656\n",
      "Iter 454400, Minibatch Loss= 0.449090, Training Accuracy= 0.78125\n",
      "Iter 455680, Minibatch Loss= 0.385504, Training Accuracy= 0.83654\n",
      "Iter 456960, Minibatch Loss= 0.405030, Training Accuracy= 0.82812\n",
      "Iter 458240, Minibatch Loss= 0.472048, Training Accuracy= 0.72656\n",
      "Iter 459520, Minibatch Loss= 0.446757, Training Accuracy= 0.78125\n",
      "Iter 460800, Minibatch Loss= 0.383148, Training Accuracy= 0.83654\n",
      "Iter 462080, Minibatch Loss= 0.403004, Training Accuracy= 0.82812\n",
      "Iter 463360, Minibatch Loss= 0.470013, Training Accuracy= 0.72656\n",
      "Iter 464640, Minibatch Loss= 0.444253, Training Accuracy= 0.78125\n",
      "Iter 465920, Minibatch Loss= 0.380676, Training Accuracy= 0.83654\n",
      "Iter 467200, Minibatch Loss= 0.400853, Training Accuracy= 0.82812\n",
      "Iter 468480, Minibatch Loss= 0.467828, Training Accuracy= 0.72656\n",
      "Iter 469760, Minibatch Loss= 0.441557, Training Accuracy= 0.78125\n",
      "Iter 471040, Minibatch Loss= 0.378076, Training Accuracy= 0.83654\n",
      "Iter 472320, Minibatch Loss= 0.398562, Training Accuracy= 0.82812\n",
      "Iter 473600, Minibatch Loss= 0.465473, Training Accuracy= 0.72656\n",
      "Iter 474880, Minibatch Loss= 0.438642, Training Accuracy= 0.78125\n",
      "Iter 476160, Minibatch Loss= 0.375330, Training Accuracy= 0.83654\n",
      "Iter 477440, Minibatch Loss= 0.396109, Training Accuracy= 0.82812\n",
      "Iter 478720, Minibatch Loss= 0.462927, Training Accuracy= 0.73438\n",
      "Iter 480000, Minibatch Loss= 0.435479, Training Accuracy= 0.78125\n",
      "Iter 481280, Minibatch Loss= 0.372423, Training Accuracy= 0.83654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 482560, Minibatch Loss= 0.393474, Training Accuracy= 0.82812\n",
      "Iter 483840, Minibatch Loss= 0.460165, Training Accuracy= 0.74219\n",
      "Iter 485120, Minibatch Loss= 0.432039, Training Accuracy= 0.78125\n",
      "Iter 486400, Minibatch Loss= 0.369329, Training Accuracy= 0.83654\n",
      "Iter 487680, Minibatch Loss= 0.390632, Training Accuracy= 0.82812\n",
      "Iter 488960, Minibatch Loss= 0.457157, Training Accuracy= 0.75781\n",
      "Iter 490240, Minibatch Loss= 0.428290, Training Accuracy= 0.78125\n",
      "Iter 491520, Minibatch Loss= 0.366020, Training Accuracy= 0.83654\n",
      "Iter 492800, Minibatch Loss= 0.387551, Training Accuracy= 0.84375\n",
      "Iter 494080, Minibatch Loss= 0.453872, Training Accuracy= 0.75000\n",
      "Iter 495360, Minibatch Loss= 0.424206, Training Accuracy= 0.78125\n",
      "Iter 496640, Minibatch Loss= 0.362453, Training Accuracy= 0.83654\n",
      "Iter 497920, Minibatch Loss= 0.384199, Training Accuracy= 0.84375\n",
      "Iter 499200, Minibatch Loss= 0.450271, Training Accuracy= 0.75781\n",
      "Iter 500480, Minibatch Loss= 0.419783, Training Accuracy= 0.78906\n",
      "Iter 501760, Minibatch Loss= 0.358567, Training Accuracy= 0.83654\n",
      "Iter 503040, Minibatch Loss= 0.380532, Training Accuracy= 0.84375\n",
      "Iter 504320, Minibatch Loss= 0.446314, Training Accuracy= 0.77344\n",
      "Iter 505600, Minibatch Loss= 0.415058, Training Accuracy= 0.79688\n",
      "Iter 506880, Minibatch Loss= 0.354285, Training Accuracy= 0.84615\n",
      "Iter 508160, Minibatch Loss= 0.376501, Training Accuracy= 0.84375\n",
      "Iter 509440, Minibatch Loss= 0.441955, Training Accuracy= 0.78125\n",
      "Iter 510720, Minibatch Loss= 0.410171, Training Accuracy= 0.80469\n",
      "Iter 512000, Minibatch Loss= 0.349533, Training Accuracy= 0.84615\n",
      "Iter 513280, Minibatch Loss= 0.372050, Training Accuracy= 0.85156\n",
      "Iter 514560, Minibatch Loss= 0.437151, Training Accuracy= 0.78125\n",
      "Iter 515840, Minibatch Loss= 0.405458, Training Accuracy= 0.82031\n",
      "Iter 517120, Minibatch Loss= 0.344390, Training Accuracy= 0.84615\n",
      "Iter 518400, Minibatch Loss= 0.367131, Training Accuracy= 0.85156\n",
      "Iter 519680, Minibatch Loss= 0.431887, Training Accuracy= 0.78125\n",
      "Iter 520960, Minibatch Loss= 0.401564, Training Accuracy= 0.82812\n",
      "Iter 522240, Minibatch Loss= 0.339511, Training Accuracy= 0.86538\n",
      "Iter 523520, Minibatch Loss= 0.361733, Training Accuracy= 0.85156\n",
      "Iter 524800, Minibatch Loss= 0.426351, Training Accuracy= 0.78125\n",
      "Iter 526080, Minibatch Loss= 0.399559, Training Accuracy= 0.83594\n",
      "Iter 527360, Minibatch Loss= 0.336628, Training Accuracy= 0.85577\n",
      "Iter 528640, Minibatch Loss= 0.355988, Training Accuracy= 0.85156\n",
      "Iter 529920, Minibatch Loss= 0.421290, Training Accuracy= 0.78906\n",
      "Iter 531200, Minibatch Loss= 0.400441, Training Accuracy= 0.82812\n",
      "Iter 532480, Minibatch Loss= 0.336618, Training Accuracy= 0.83654\n",
      "Iter 533760, Minibatch Loss= 0.350252, Training Accuracy= 0.85156\n",
      "Iter 535040, Minibatch Loss= 0.417011, Training Accuracy= 0.79688\n",
      "Iter 536320, Minibatch Loss= 0.401654, Training Accuracy= 0.85156\n",
      "Iter 537600, Minibatch Loss= 0.336072, Training Accuracy= 0.83654\n",
      "Iter 538880, Minibatch Loss= 0.344486, Training Accuracy= 0.85156\n",
      "Iter 540160, Minibatch Loss= 0.412211, Training Accuracy= 0.82812\n",
      "Iter 541440, Minibatch Loss= 0.400335, Training Accuracy= 0.84375\n",
      "Iter 542720, Minibatch Loss= 0.333884, Training Accuracy= 0.83654\n",
      "Iter 544000, Minibatch Loss= 0.338562, Training Accuracy= 0.85156\n",
      "Iter 545280, Minibatch Loss= 0.406638, Training Accuracy= 0.83594\n",
      "Iter 546560, Minibatch Loss= 0.397415, Training Accuracy= 0.85156\n",
      "Iter 547840, Minibatch Loss= 0.331056, Training Accuracy= 0.83654\n",
      "Iter 549120, Minibatch Loss= 0.332467, Training Accuracy= 0.85156\n",
      "Iter 550400, Minibatch Loss= 0.400466, Training Accuracy= 0.83594\n",
      "Iter 551680, Minibatch Loss= 0.393479, Training Accuracy= 0.84375\n",
      "Iter 552960, Minibatch Loss= 0.327965, Training Accuracy= 0.83654\n",
      "Iter 554240, Minibatch Loss= 0.326176, Training Accuracy= 0.85938\n",
      "Iter 555520, Minibatch Loss= 0.393756, Training Accuracy= 0.84375\n",
      "Iter 556800, Minibatch Loss= 0.388659, Training Accuracy= 0.85156\n",
      "Iter 558080, Minibatch Loss= 0.324754, Training Accuracy= 0.84615\n",
      "Iter 559360, Minibatch Loss= 0.319672, Training Accuracy= 0.86719\n",
      "Iter 560640, Minibatch Loss= 0.386526, Training Accuracy= 0.85156\n",
      "Iter 561920, Minibatch Loss= 0.382937, Training Accuracy= 0.85156\n",
      "Iter 563200, Minibatch Loss= 0.321503, Training Accuracy= 0.84615\n",
      "Iter 564480, Minibatch Loss= 0.312952, Training Accuracy= 0.87500\n",
      "Iter 565760, Minibatch Loss= 0.378780, Training Accuracy= 0.85156\n",
      "Iter 567040, Minibatch Loss= 0.376224, Training Accuracy= 0.86719\n",
      "Iter 568320, Minibatch Loss= 0.318279, Training Accuracy= 0.85577\n",
      "Iter 569600, Minibatch Loss= 0.306023, Training Accuracy= 0.89062\n",
      "Iter 570880, Minibatch Loss= 0.370522, Training Accuracy= 0.85938\n",
      "Iter 572160, Minibatch Loss= 0.368379, Training Accuracy= 0.86719\n",
      "Iter 573440, Minibatch Loss= 0.315142, Training Accuracy= 0.86538\n",
      "Iter 574720, Minibatch Loss= 0.298904, Training Accuracy= 0.90625\n",
      "Iter 576000, Minibatch Loss= 0.361767, Training Accuracy= 0.85938\n",
      "Iter 577280, Minibatch Loss= 0.359236, Training Accuracy= 0.87500\n",
      "Iter 578560, Minibatch Loss= 0.312155, Training Accuracy= 0.86538\n",
      "Iter 579840, Minibatch Loss= 0.291629, Training Accuracy= 0.89844\n",
      "Iter 581120, Minibatch Loss= 0.352546, Training Accuracy= 0.88281\n",
      "Iter 582400, Minibatch Loss= 0.348611, Training Accuracy= 0.89062\n",
      "Iter 583680, Minibatch Loss= 0.309375, Training Accuracy= 0.86538\n",
      "Iter 584960, Minibatch Loss= 0.284254, Training Accuracy= 0.90625\n",
      "Iter 586240, Minibatch Loss= 0.342912, Training Accuracy= 0.88281\n",
      "Iter 587520, Minibatch Loss= 0.336331, Training Accuracy= 0.88281\n",
      "Iter 588800, Minibatch Loss= 0.306837, Training Accuracy= 0.88462\n",
      "Iter 590080, Minibatch Loss= 0.276861, Training Accuracy= 0.91406\n",
      "Iter 591360, Minibatch Loss= 0.332940, Training Accuracy= 0.89844\n",
      "Iter 592640, Minibatch Loss= 0.322260, Training Accuracy= 0.89062\n",
      "Iter 593920, Minibatch Loss= 0.304520, Training Accuracy= 0.87500\n",
      "Iter 595200, Minibatch Loss= 0.269564, Training Accuracy= 0.92188\n",
      "Iter 596480, Minibatch Loss= 0.322736, Training Accuracy= 0.89062\n",
      "Iter 597760, Minibatch Loss= 0.306334, Training Accuracy= 0.89062\n",
      "Iter 599040, Minibatch Loss= 0.302291, Training Accuracy= 0.87500\n",
      "Iter 600320, Minibatch Loss= 0.262506, Training Accuracy= 0.92969\n",
      "Iter 601600, Minibatch Loss= 0.312422, Training Accuracy= 0.89844\n",
      "Iter 602880, Minibatch Loss= 0.288605, Training Accuracy= 0.89062\n",
      "Iter 604160, Minibatch Loss= 0.299835, Training Accuracy= 0.88462\n",
      "Iter 605440, Minibatch Loss= 0.255830, Training Accuracy= 0.92969\n",
      "Iter 606720, Minibatch Loss= 0.302123, Training Accuracy= 0.89844\n",
      "Iter 608000, Minibatch Loss= 0.269272, Training Accuracy= 0.89844\n",
      "Iter 609280, Minibatch Loss= 0.296544, Training Accuracy= 0.91346\n",
      "Iter 610560, Minibatch Loss= 0.249626, Training Accuracy= 0.93750\n",
      "Iter 611840, Minibatch Loss= 0.291907, Training Accuracy= 0.89844\n",
      "Iter 613120, Minibatch Loss= 0.248674, Training Accuracy= 0.92188\n",
      "Iter 614400, Minibatch Loss= 0.291297, Training Accuracy= 0.91346\n",
      "Iter 615680, Minibatch Loss= 0.243849, Training Accuracy= 0.96094\n",
      "Iter 616960, Minibatch Loss= 0.281795, Training Accuracy= 0.90625\n",
      "Iter 618240, Minibatch Loss= 0.227506, Training Accuracy= 0.92188\n",
      "Iter 619520, Minibatch Loss= 0.277241, Training Accuracy= 0.91346\n",
      "Iter 620800, Minibatch Loss= 0.227275, Training Accuracy= 0.96094\n",
      "Iter 622080, Minibatch Loss= 0.244346, Training Accuracy= 0.92188\n",
      "Iter 623360, Minibatch Loss= 0.176428, Training Accuracy= 0.94531\n",
      "Iter 624640, Minibatch Loss= 0.220765, Training Accuracy= 0.92308\n",
      "Iter 625920, Minibatch Loss= 0.216626, Training Accuracy= 0.93750\n",
      "Iter 627200, Minibatch Loss= 0.234006, Training Accuracy= 0.94531\n",
      "Iter 628480, Minibatch Loss= 0.164634, Training Accuracy= 0.94531\n",
      "Iter 629760, Minibatch Loss= 0.166788, Training Accuracy= 0.97115\n",
      "Iter 631040, Minibatch Loss= 0.190804, Training Accuracy= 0.97656\n",
      "Iter 632320, Minibatch Loss= 0.214511, Training Accuracy= 0.94531\n",
      "Iter 633600, Minibatch Loss= 0.148806, Training Accuracy= 0.95312\n",
      "Iter 634880, Minibatch Loss= 0.161577, Training Accuracy= 0.99038\n",
      "Iter 636160, Minibatch Loss= 0.282984, Training Accuracy= 0.91406\n",
      "Iter 637440, Minibatch Loss= 0.246762, Training Accuracy= 0.89844\n",
      "Iter 638720, Minibatch Loss= 0.154851, Training Accuracy= 0.96094\n",
      "Iter 640000, Minibatch Loss= 0.157083, Training Accuracy= 0.96154\n",
      "Iter 641280, Minibatch Loss= 0.181466, Training Accuracy= 0.97656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 642560, Minibatch Loss= 0.203376, Training Accuracy= 0.95312\n",
      "Iter 643840, Minibatch Loss= 0.136131, Training Accuracy= 0.96094\n",
      "Iter 645120, Minibatch Loss= 0.146199, Training Accuracy= 0.99038\n",
      "Iter 646400, Minibatch Loss= 0.175118, Training Accuracy= 0.97656\n",
      "Iter 647680, Minibatch Loss= 0.193214, Training Accuracy= 0.96094\n",
      "Iter 648960, Minibatch Loss= 0.125702, Training Accuracy= 0.96094\n",
      "Iter 650240, Minibatch Loss= 0.139424, Training Accuracy= 0.99038\n",
      "Iter 651520, Minibatch Loss= 0.169696, Training Accuracy= 0.97656\n",
      "Iter 652800, Minibatch Loss= 0.185597, Training Accuracy= 0.96094\n",
      "Iter 654080, Minibatch Loss= 0.118102, Training Accuracy= 0.96094\n",
      "Iter 655360, Minibatch Loss= 0.134150, Training Accuracy= 0.99038\n",
      "Iter 656640, Minibatch Loss= 0.164783, Training Accuracy= 0.97656\n",
      "Iter 657920, Minibatch Loss= 0.179395, Training Accuracy= 0.96094\n",
      "Iter 659200, Minibatch Loss= 0.112099, Training Accuracy= 0.96094\n",
      "Iter 660480, Minibatch Loss= 0.129541, Training Accuracy= 0.99038\n",
      "Iter 661760, Minibatch Loss= 0.160578, Training Accuracy= 0.96875\n",
      "Iter 663040, Minibatch Loss= 0.174179, Training Accuracy= 0.95312\n",
      "Iter 664320, Minibatch Loss= 0.107132, Training Accuracy= 0.96094\n",
      "Iter 665600, Minibatch Loss= 0.125233, Training Accuracy= 0.99038\n",
      "Iter 666880, Minibatch Loss= 0.157522, Training Accuracy= 0.96094\n",
      "Iter 668160, Minibatch Loss= 0.169783, Training Accuracy= 0.96094\n",
      "Iter 669440, Minibatch Loss= 0.102938, Training Accuracy= 0.96094\n",
      "Iter 670720, Minibatch Loss= 0.121463, Training Accuracy= 0.99038\n",
      "Iter 672000, Minibatch Loss= 0.155500, Training Accuracy= 0.96875\n",
      "Iter 673280, Minibatch Loss= 0.166113, Training Accuracy= 0.96094\n",
      "Iter 674560, Minibatch Loss= 0.099407, Training Accuracy= 0.96094\n",
      "Iter 675840, Minibatch Loss= 0.118338, Training Accuracy= 0.99038\n",
      "Iter 677120, Minibatch Loss= 0.154277, Training Accuracy= 0.96875\n",
      "Iter 678400, Minibatch Loss= 0.163048, Training Accuracy= 0.96094\n",
      "Iter 679680, Minibatch Loss= 0.096410, Training Accuracy= 0.96094\n",
      "Iter 680960, Minibatch Loss= 0.115664, Training Accuracy= 0.99038\n",
      "Iter 682240, Minibatch Loss= 0.153926, Training Accuracy= 0.93750\n",
      "Iter 683520, Minibatch Loss= 0.160662, Training Accuracy= 0.96875\n",
      "Iter 684800, Minibatch Loss= 0.093828, Training Accuracy= 0.96094\n",
      "Iter 686080, Minibatch Loss= 0.113294, Training Accuracy= 0.99038\n",
      "Iter 687360, Minibatch Loss= 0.154473, Training Accuracy= 0.92969\n",
      "Iter 688640, Minibatch Loss= 0.159568, Training Accuracy= 0.98438\n",
      "Iter 689920, Minibatch Loss= 0.091567, Training Accuracy= 0.96094\n",
      "Iter 691200, Minibatch Loss= 0.111106, Training Accuracy= 0.99038\n",
      "Iter 692480, Minibatch Loss= 0.155665, Training Accuracy= 0.92969\n",
      "Iter 693760, Minibatch Loss= 0.162692, Training Accuracy= 0.98438\n",
      "Iter 695040, Minibatch Loss= 0.089585, Training Accuracy= 0.96094\n",
      "Iter 696320, Minibatch Loss= 0.108907, Training Accuracy= 0.99038\n",
      "Iter 697600, Minibatch Loss= 0.155632, Training Accuracy= 0.92969\n",
      "Iter 698880, Minibatch Loss= 0.828869, Training Accuracy= 0.68750\n",
      "Iter 700160, Minibatch Loss= 0.236912, Training Accuracy= 0.89844\n",
      "Iter 701440, Minibatch Loss= 0.169178, Training Accuracy= 0.89423\n",
      "Iter 702720, Minibatch Loss= 0.163448, Training Accuracy= 0.96875\n",
      "Iter 704000, Minibatch Loss= 0.170387, Training Accuracy= 0.96094\n",
      "Iter 705280, Minibatch Loss= 0.103921, Training Accuracy= 0.96094\n",
      "Iter 706560, Minibatch Loss= 0.119560, Training Accuracy= 0.99038\n",
      "Iter 707840, Minibatch Loss= 0.146917, Training Accuracy= 0.98438\n",
      "Iter 709120, Minibatch Loss= 0.159595, Training Accuracy= 0.95312\n",
      "Iter 710400, Minibatch Loss= 0.096033, Training Accuracy= 0.96094\n",
      "Iter 711680, Minibatch Loss= 0.113826, Training Accuracy= 0.99038\n",
      "Iter 712960, Minibatch Loss= 0.141745, Training Accuracy= 0.98438\n",
      "Iter 714240, Minibatch Loss= 0.154167, Training Accuracy= 0.95312\n",
      "Iter 715520, Minibatch Loss= 0.091889, Training Accuracy= 0.96094\n",
      "Iter 716800, Minibatch Loss= 0.109486, Training Accuracy= 0.99038\n",
      "Iter 718080, Minibatch Loss= 0.137799, Training Accuracy= 0.98438\n",
      "Iter 719360, Minibatch Loss= 0.150093, Training Accuracy= 0.95312\n",
      "Iter 720640, Minibatch Loss= 0.089003, Training Accuracy= 0.96094\n",
      "Iter 721920, Minibatch Loss= 0.106180, Training Accuracy= 0.99038\n",
      "Iter 723200, Minibatch Loss= 0.134604, Training Accuracy= 0.98438\n",
      "Iter 724480, Minibatch Loss= 0.146749, Training Accuracy= 0.95312\n",
      "Iter 725760, Minibatch Loss= 0.086729, Training Accuracy= 0.96094\n",
      "Iter 727040, Minibatch Loss= 0.103521, Training Accuracy= 0.99038\n",
      "Iter 728320, Minibatch Loss= 0.131989, Training Accuracy= 0.98438\n",
      "Iter 729600, Minibatch Loss= 0.143914, Training Accuracy= 0.95312\n",
      "Iter 730880, Minibatch Loss= 0.084822, Training Accuracy= 0.96094\n",
      "Iter 732160, Minibatch Loss= 0.101285, Training Accuracy= 0.99038\n",
      "Iter 733440, Minibatch Loss= 0.129827, Training Accuracy= 0.98438\n",
      "Iter 734720, Minibatch Loss= 0.141454, Training Accuracy= 0.95312\n",
      "Iter 736000, Minibatch Loss= 0.083172, Training Accuracy= 0.96094\n",
      "Iter 737280, Minibatch Loss= 0.099342, Training Accuracy= 0.99038\n",
      "Iter 738560, Minibatch Loss= 0.127993, Training Accuracy= 0.98438\n",
      "Iter 739840, Minibatch Loss= 0.139273, Training Accuracy= 0.95312\n",
      "Iter 741120, Minibatch Loss= 0.081715, Training Accuracy= 0.96094\n",
      "Iter 742400, Minibatch Loss= 0.097613, Training Accuracy= 0.99038\n",
      "Iter 743680, Minibatch Loss= 0.126376, Training Accuracy= 0.98438\n",
      "Iter 744960, Minibatch Loss= 0.137307, Training Accuracy= 0.95312\n",
      "Iter 746240, Minibatch Loss= 0.080413, Training Accuracy= 0.96094\n",
      "Iter 747520, Minibatch Loss= 0.096046, Training Accuracy= 0.99038\n",
      "Iter 748800, Minibatch Loss= 0.124874, Training Accuracy= 0.98438\n",
      "Iter 750080, Minibatch Loss= 0.135508, Training Accuracy= 0.95312\n",
      "Iter 751360, Minibatch Loss= 0.079234, Training Accuracy= 0.96094\n",
      "Iter 752640, Minibatch Loss= 0.094608, Training Accuracy= 0.98077\n",
      "Iter 753920, Minibatch Loss= 0.123402, Training Accuracy= 0.98438\n",
      "Iter 755200, Minibatch Loss= 0.133842, Training Accuracy= 0.95312\n",
      "Iter 756480, Minibatch Loss= 0.078159, Training Accuracy= 0.96094\n",
      "Iter 757760, Minibatch Loss= 0.093274, Training Accuracy= 0.98077\n",
      "Iter 759040, Minibatch Loss= 0.121892, Training Accuracy= 0.98438\n",
      "Iter 760320, Minibatch Loss= 0.132285, Training Accuracy= 0.95312\n",
      "Iter 761600, Minibatch Loss= 0.077171, Training Accuracy= 0.96094\n",
      "Iter 762880, Minibatch Loss= 0.092026, Training Accuracy= 0.98077\n",
      "Iter 764160, Minibatch Loss= 0.120291, Training Accuracy= 0.98438\n",
      "Iter 765440, Minibatch Loss= 0.130820, Training Accuracy= 0.95312\n",
      "Iter 766720, Minibatch Loss= 0.076258, Training Accuracy= 0.96094\n",
      "Iter 768000, Minibatch Loss= 0.090851, Training Accuracy= 0.98077\n",
      "Iter 769280, Minibatch Loss= 0.118570, Training Accuracy= 0.98438\n",
      "Iter 770560, Minibatch Loss= 0.129432, Training Accuracy= 0.95312\n",
      "Iter 771840, Minibatch Loss= 0.075411, Training Accuracy= 0.96094\n",
      "Iter 773120, Minibatch Loss= 0.089741, Training Accuracy= 0.98077\n",
      "Iter 774400, Minibatch Loss= 0.116735, Training Accuracy= 0.98438\n",
      "Iter 775680, Minibatch Loss= 0.128114, Training Accuracy= 0.95312\n",
      "Iter 776960, Minibatch Loss= 0.074618, Training Accuracy= 0.96094\n",
      "Iter 778240, Minibatch Loss= 0.088689, Training Accuracy= 0.98077\n",
      "Iter 779520, Minibatch Loss= 0.114839, Training Accuracy= 0.98438\n",
      "Iter 780800, Minibatch Loss= 0.126860, Training Accuracy= 0.95312\n",
      "Iter 782080, Minibatch Loss= 0.073872, Training Accuracy= 0.96094\n",
      "Iter 783360, Minibatch Loss= 0.087692, Training Accuracy= 0.98077\n",
      "Iter 784640, Minibatch Loss= 0.112968, Training Accuracy= 0.98438\n",
      "Iter 785920, Minibatch Loss= 0.125666, Training Accuracy= 0.95312\n",
      "Iter 787200, Minibatch Loss= 0.073163, Training Accuracy= 0.96094\n",
      "Iter 788480, Minibatch Loss= 0.086745, Training Accuracy= 0.98077\n",
      "Iter 789760, Minibatch Loss= 0.111198, Training Accuracy= 0.97656\n",
      "Iter 791040, Minibatch Loss= 0.124525, Training Accuracy= 0.95312\n",
      "Iter 792320, Minibatch Loss= 0.072486, Training Accuracy= 0.96094\n",
      "Iter 793600, Minibatch Loss= 0.085844, Training Accuracy= 0.98077\n",
      "Iter 794880, Minibatch Loss= 0.109558, Training Accuracy= 0.97656\n",
      "Iter 796160, Minibatch Loss= 0.123433, Training Accuracy= 0.95312\n",
      "Iter 797440, Minibatch Loss= 0.071840, Training Accuracy= 0.96094\n",
      "Iter 798720, Minibatch Loss= 0.084987, Training Accuracy= 0.98077\n",
      "Iter 800000, Minibatch Loss= 0.108051, Training Accuracy= 0.97656\n",
      "Iter 801280, Minibatch Loss= 0.122385, Training Accuracy= 0.95312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 802560, Minibatch Loss= 0.071222, Training Accuracy= 0.96094\n",
      "Iter 803840, Minibatch Loss= 0.084168, Training Accuracy= 0.98077\n",
      "Iter 805120, Minibatch Loss= 0.106694, Training Accuracy= 0.97656\n",
      "Iter 806400, Minibatch Loss= 0.121377, Training Accuracy= 0.95312\n",
      "Iter 807680, Minibatch Loss= 0.070632, Training Accuracy= 0.96094\n",
      "Iter 808960, Minibatch Loss= 0.083385, Training Accuracy= 0.98077\n",
      "Iter 810240, Minibatch Loss= 0.105516, Training Accuracy= 0.97656\n",
      "Iter 811520, Minibatch Loss= 0.120407, Training Accuracy= 0.95312\n",
      "Iter 812800, Minibatch Loss= 0.070067, Training Accuracy= 0.96094\n",
      "Iter 814080, Minibatch Loss= 0.082635, Training Accuracy= 0.98077\n",
      "Iter 815360, Minibatch Loss= 0.104562, Training Accuracy= 0.97656\n",
      "Iter 816640, Minibatch Loss= 0.119471, Training Accuracy= 0.95312\n",
      "Iter 817920, Minibatch Loss= 0.069526, Training Accuracy= 0.96094\n",
      "Iter 819200, Minibatch Loss= 0.081915, Training Accuracy= 0.98077\n",
      "Iter 820480, Minibatch Loss= 0.103913, Training Accuracy= 0.97656\n",
      "Iter 821760, Minibatch Loss= 0.118566, Training Accuracy= 0.95312\n",
      "Iter 823040, Minibatch Loss= 0.069006, Training Accuracy= 0.96094\n",
      "Iter 824320, Minibatch Loss= 0.081223, Training Accuracy= 0.98077\n",
      "Iter 825600, Minibatch Loss= 0.103681, Training Accuracy= 0.97656\n",
      "Iter 826880, Minibatch Loss= 0.117691, Training Accuracy= 0.95312\n",
      "Iter 828160, Minibatch Loss= 0.068508, Training Accuracy= 0.96094\n",
      "Iter 829440, Minibatch Loss= 0.080558, Training Accuracy= 0.98077\n",
      "Iter 830720, Minibatch Loss= 0.103979, Training Accuracy= 0.97656\n",
      "Iter 832000, Minibatch Loss= 0.116843, Training Accuracy= 0.95312\n",
      "Iter 833280, Minibatch Loss= 0.068029, Training Accuracy= 0.96094\n",
      "Iter 834560, Minibatch Loss= 0.079917, Training Accuracy= 0.98077\n",
      "Iter 835840, Minibatch Loss= 0.104908, Training Accuracy= 0.96875\n",
      "Iter 837120, Minibatch Loss= 0.116021, Training Accuracy= 0.95312\n",
      "Iter 838400, Minibatch Loss= 0.067568, Training Accuracy= 0.96094\n",
      "Iter 839680, Minibatch Loss= 0.079298, Training Accuracy= 0.98077\n",
      "Iter 840960, Minibatch Loss= 0.106476, Training Accuracy= 0.96875\n",
      "Iter 842240, Minibatch Loss= 0.115222, Training Accuracy= 0.95312\n",
      "Iter 843520, Minibatch Loss= 0.067124, Training Accuracy= 0.96094\n",
      "Iter 844800, Minibatch Loss= 0.078701, Training Accuracy= 0.99038\n",
      "Iter 846080, Minibatch Loss= 0.108545, Training Accuracy= 0.96875\n",
      "Iter 847360, Minibatch Loss= 0.114446, Training Accuracy= 0.95312\n",
      "Iter 848640, Minibatch Loss= 0.066697, Training Accuracy= 0.96094\n",
      "Iter 849920, Minibatch Loss= 0.078123, Training Accuracy= 0.99038\n",
      "Iter 851200, Minibatch Loss= 0.110929, Training Accuracy= 0.96875\n",
      "Iter 852480, Minibatch Loss= 0.113691, Training Accuracy= 0.95312\n",
      "Iter 853760, Minibatch Loss= 0.066285, Training Accuracy= 0.96094\n",
      "Iter 855040, Minibatch Loss= 0.077563, Training Accuracy= 0.99038\n",
      "Iter 856320, Minibatch Loss= 0.113368, Training Accuracy= 0.96875\n",
      "Iter 857600, Minibatch Loss= 0.112955, Training Accuracy= 0.95312\n",
      "Iter 858880, Minibatch Loss= 0.065887, Training Accuracy= 0.96094\n",
      "Iter 860160, Minibatch Loss= 0.077020, Training Accuracy= 0.99038\n",
      "Iter 861440, Minibatch Loss= 0.115557, Training Accuracy= 0.96875\n",
      "Iter 862720, Minibatch Loss= 0.112236, Training Accuracy= 0.95312\n",
      "Iter 864000, Minibatch Loss= 0.065502, Training Accuracy= 0.96094\n",
      "Iter 865280, Minibatch Loss= 0.076494, Training Accuracy= 0.99038\n",
      "Iter 866560, Minibatch Loss= 0.117253, Training Accuracy= 0.96875\n",
      "Iter 867840, Minibatch Loss= 0.111533, Training Accuracy= 0.95312\n",
      "Iter 869120, Minibatch Loss= 0.065130, Training Accuracy= 0.96094\n",
      "Iter 870400, Minibatch Loss= 0.075983, Training Accuracy= 0.99038\n",
      "Iter 871680, Minibatch Loss= 0.118220, Training Accuracy= 0.96875\n",
      "Iter 872960, Minibatch Loss= 0.110845, Training Accuracy= 0.95312\n",
      "Iter 874240, Minibatch Loss= 0.064769, Training Accuracy= 0.96094\n",
      "Iter 875520, Minibatch Loss= 0.075486, Training Accuracy= 0.99038\n",
      "Iter 876800, Minibatch Loss= 0.118366, Training Accuracy= 0.96875\n",
      "Iter 878080, Minibatch Loss= 0.110174, Training Accuracy= 0.95312\n",
      "Iter 879360, Minibatch Loss= 0.064420, Training Accuracy= 0.96094\n",
      "Iter 880640, Minibatch Loss= 0.075001, Training Accuracy= 0.99038\n",
      "Iter 881920, Minibatch Loss= 0.117771, Training Accuracy= 0.96875\n",
      "Iter 883200, Minibatch Loss= 0.109520, Training Accuracy= 0.95312\n",
      "Iter 884480, Minibatch Loss= 0.064084, Training Accuracy= 0.96094\n",
      "Iter 885760, Minibatch Loss= 0.074528, Training Accuracy= 0.99038\n",
      "Iter 887040, Minibatch Loss= 0.116642, Training Accuracy= 0.96875\n",
      "Iter 888320, Minibatch Loss= 0.108883, Training Accuracy= 0.95312\n",
      "Iter 889600, Minibatch Loss= 0.063759, Training Accuracy= 0.96094\n",
      "Iter 890880, Minibatch Loss= 0.074066, Training Accuracy= 0.99038\n",
      "Iter 892160, Minibatch Loss= 0.115167, Training Accuracy= 0.96875\n",
      "Iter 893440, Minibatch Loss= 0.108262, Training Accuracy= 0.95312\n",
      "Iter 894720, Minibatch Loss= 0.063445, Training Accuracy= 0.96094\n",
      "Iter 896000, Minibatch Loss= 0.073615, Training Accuracy= 0.99038\n",
      "Iter 897280, Minibatch Loss= 0.113457, Training Accuracy= 0.96875\n",
      "Iter 898560, Minibatch Loss= 0.107654, Training Accuracy= 0.95312\n",
      "Iter 899840, Minibatch Loss= 0.063142, Training Accuracy= 0.96094\n",
      "Iter 901120, Minibatch Loss= 0.073174, Training Accuracy= 0.99038\n",
      "Iter 902400, Minibatch Loss= 0.111536, Training Accuracy= 0.96875\n",
      "Iter 903680, Minibatch Loss= 0.107060, Training Accuracy= 0.95312\n",
      "Iter 904960, Minibatch Loss= 0.062847, Training Accuracy= 0.96094\n",
      "Iter 906240, Minibatch Loss= 0.072744, Training Accuracy= 0.99038\n",
      "Iter 907520, Minibatch Loss= 0.109403, Training Accuracy= 0.96875\n",
      "Iter 908800, Minibatch Loss= 0.106478, Training Accuracy= 0.95312\n",
      "Iter 910080, Minibatch Loss= 0.062562, Training Accuracy= 0.96094\n",
      "Iter 911360, Minibatch Loss= 0.072323, Training Accuracy= 0.99038\n",
      "Iter 912640, Minibatch Loss= 0.107076, Training Accuracy= 0.96875\n",
      "Iter 913920, Minibatch Loss= 0.105908, Training Accuracy= 0.95312\n",
      "Iter 915200, Minibatch Loss= 0.062284, Training Accuracy= 0.96094\n",
      "Iter 916480, Minibatch Loss= 0.071912, Training Accuracy= 0.99038\n",
      "Iter 917760, Minibatch Loss= 0.104527, Training Accuracy= 0.96875\n",
      "Iter 919040, Minibatch Loss= 0.105350, Training Accuracy= 0.95312\n",
      "Iter 920320, Minibatch Loss= 0.062015, Training Accuracy= 0.96094\n",
      "Iter 921600, Minibatch Loss= 0.071510, Training Accuracy= 0.99038\n",
      "Iter 922880, Minibatch Loss= 0.101748, Training Accuracy= 0.97656\n",
      "Iter 924160, Minibatch Loss= 0.104802, Training Accuracy= 0.95312\n",
      "Iter 925440, Minibatch Loss= 0.061754, Training Accuracy= 0.96094\n",
      "Iter 926720, Minibatch Loss= 0.071116, Training Accuracy= 0.99038\n",
      "Iter 928000, Minibatch Loss= 0.098757, Training Accuracy= 0.97656\n",
      "Iter 929280, Minibatch Loss= 0.104266, Training Accuracy= 0.95312\n",
      "Iter 930560, Minibatch Loss= 0.061500, Training Accuracy= 0.96094\n",
      "Iter 931840, Minibatch Loss= 0.070730, Training Accuracy= 0.99038\n",
      "Iter 933120, Minibatch Loss= 0.095541, Training Accuracy= 0.97656\n",
      "Iter 934400, Minibatch Loss= 0.103740, Training Accuracy= 0.95312\n",
      "Iter 935680, Minibatch Loss= 0.061253, Training Accuracy= 0.96094\n",
      "Iter 936960, Minibatch Loss= 0.070353, Training Accuracy= 0.99038\n",
      "Iter 938240, Minibatch Loss= 0.092202, Training Accuracy= 0.97656\n",
      "Iter 939520, Minibatch Loss= 0.103223, Training Accuracy= 0.95312\n",
      "Iter 940800, Minibatch Loss= 0.061013, Training Accuracy= 0.96094\n",
      "Iter 942080, Minibatch Loss= 0.069983, Training Accuracy= 0.99038\n",
      "Iter 943360, Minibatch Loss= 0.088775, Training Accuracy= 0.97656\n",
      "Iter 944640, Minibatch Loss= 0.102717, Training Accuracy= 0.95312\n",
      "Iter 945920, Minibatch Loss= 0.060780, Training Accuracy= 0.96094\n",
      "Iter 947200, Minibatch Loss= 0.069620, Training Accuracy= 0.99038\n",
      "Iter 948480, Minibatch Loss= 0.085459, Training Accuracy= 0.97656\n",
      "Iter 949760, Minibatch Loss= 0.102219, Training Accuracy= 0.95312\n",
      "Iter 951040, Minibatch Loss= 0.060553, Training Accuracy= 0.96094\n",
      "Iter 952320, Minibatch Loss= 0.069265, Training Accuracy= 0.99038\n",
      "Iter 953600, Minibatch Loss= 0.082495, Training Accuracy= 0.98438\n",
      "Iter 954880, Minibatch Loss= 0.101730, Training Accuracy= 0.95312\n",
      "Iter 956160, Minibatch Loss= 0.060332, Training Accuracy= 0.96094\n",
      "Iter 957440, Minibatch Loss= 0.068916, Training Accuracy= 0.99038\n",
      "Iter 958720, Minibatch Loss= 0.080065, Training Accuracy= 0.98438\n",
      "Iter 960000, Minibatch Loss= 0.101251, Training Accuracy= 0.95312\n",
      "Iter 961280, Minibatch Loss= 0.060118, Training Accuracy= 0.96094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 962560, Minibatch Loss= 0.068573, Training Accuracy= 0.99038\n",
      "Iter 963840, Minibatch Loss= 0.078269, Training Accuracy= 0.98438\n",
      "Iter 965120, Minibatch Loss= 0.100779, Training Accuracy= 0.95312\n",
      "Iter 966400, Minibatch Loss= 0.059909, Training Accuracy= 0.96094\n",
      "Iter 967680, Minibatch Loss= 0.068236, Training Accuracy= 0.99038\n",
      "Iter 968960, Minibatch Loss= 0.077044, Training Accuracy= 0.98438\n",
      "Iter 970240, Minibatch Loss= 0.100315, Training Accuracy= 0.95312\n",
      "Iter 971520, Minibatch Loss= 0.059708, Training Accuracy= 0.96094\n",
      "Iter 972800, Minibatch Loss= 0.067904, Training Accuracy= 0.99038\n",
      "Iter 974080, Minibatch Loss= 0.076098, Training Accuracy= 0.98438\n",
      "Iter 975360, Minibatch Loss= 0.099867, Training Accuracy= 0.95312\n",
      "Iter 976640, Minibatch Loss= 0.059518, Training Accuracy= 0.96094\n",
      "Iter 977920, Minibatch Loss= 0.067576, Training Accuracy= 0.99038\n",
      "Iter 979200, Minibatch Loss= 0.075403, Training Accuracy= 0.98438\n",
      "Iter 980480, Minibatch Loss= 0.099406, Training Accuracy= 0.95312\n",
      "Iter 981760, Minibatch Loss= 0.059322, Training Accuracy= 0.96094\n",
      "Iter 983040, Minibatch Loss= 0.067254, Training Accuracy= 0.99038\n",
      "Iter 984320, Minibatch Loss= 0.074655, Training Accuracy= 0.98438\n",
      "Iter 985600, Minibatch Loss= 0.098995, Training Accuracy= 0.95312\n",
      "Iter 986880, Minibatch Loss= 0.059148, Training Accuracy= 0.96094\n",
      "Iter 988160, Minibatch Loss= 0.066943, Training Accuracy= 0.99038\n",
      "Iter 989440, Minibatch Loss= 0.074219, Training Accuracy= 0.98438\n",
      "Iter 990720, Minibatch Loss= 0.098550, Training Accuracy= 0.95312\n",
      "Iter 992000, Minibatch Loss= 0.059001, Training Accuracy= 0.96094\n",
      "Iter 993280, Minibatch Loss= 0.066601, Training Accuracy= 0.99038\n",
      "Iter 994560, Minibatch Loss= 0.073334, Training Accuracy= 0.98438\n",
      "Iter 995840, Minibatch Loss= 0.098030, Training Accuracy= 0.95312\n",
      "Iter 997120, Minibatch Loss= 0.058722, Training Accuracy= 0.96094\n",
      "Iter 998400, Minibatch Loss= 0.066329, Training Accuracy= 0.99038\n",
      "Iter 999680, Minibatch Loss= 0.072623, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.984\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A Dynamic Recurrent Neural Network (LSTM) implementation example using\n",
    "TensorFlow library. This example is using a toy dataset to classify linear\n",
    "sequences. The generated sequences have variable length.\n",
    "Long Short Term Memory paper: http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "# ====================\n",
    "#  TOY DATA GENERATOR\n",
    "# ====================\n",
    "class ToySequenceData(object):\n",
    "    \"\"\" Generate sequence of data with dynamic length.\n",
    "    This class generate samples for training:\n",
    "    - Class 0: linear sequences (i.e. [0, 1, 2, 3,...])\n",
    "    - Class 1: random sequences (i.e. [1, 3, 10, 7,...])\n",
    "    NOTICE:\n",
    "    We have to pad each sequence to reach 'max_seq_len' for TensorFlow\n",
    "    consistency (we cannot feed a numpy array with inconsistent\n",
    "    dimensions). The dynamic calculation will then be perform thanks to\n",
    "    'seqlen' attribute that records every actual sequence length.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_samples=1000, max_seq_len=20, min_seq_len=3,\n",
    "                 max_value=1000):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.seqlen = []\n",
    "        for i in range(n_samples):\n",
    "            # Random sequence length\n",
    "            len = random.randint(min_seq_len, max_seq_len)\n",
    "            # Monitor sequence length for TensorFlow dynamic calculation\n",
    "            self.seqlen.append(len)\n",
    "            # Add a random or linear int sequence (50% prob)\n",
    "            if random.random() < .5:\n",
    "                # Generate a linear sequence\n",
    "                rand_start = random.randint(0, max_value - len)\n",
    "                s = [[float(i)/max_value] for i in\n",
    "                     range(rand_start, rand_start + len)]\n",
    "                # Pad sequence for dimension consistency\n",
    "                s += [[0.] for i in range(max_seq_len - len)]\n",
    "                self.data.append(s)\n",
    "                self.labels.append([1., 0.])\n",
    "            else:\n",
    "                # Generate a random sequence\n",
    "                s = [[float(random.randint(0, max_value))/max_value]\n",
    "                     for i in range(len)]\n",
    "                # Pad sequence for dimension consistency\n",
    "                s += [[0.] for i in range(max_seq_len - len)]\n",
    "                self.data.append(s)\n",
    "                self.labels.append([0., 1.])\n",
    "        self.batch_id = 0\n",
    "\n",
    "    def next(self, batch_size):\n",
    "        \"\"\" Return a batch of data. When dataset end is reached, start over.\n",
    "        \"\"\"\n",
    "        if self.batch_id == len(self.data):\n",
    "            self.batch_id = 0\n",
    "        batch_data = (self.data[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_labels = (self.labels[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        self.batch_id = min(self.batch_id + batch_size, len(self.data))\n",
    "        return batch_data, batch_labels, batch_seqlen\n",
    "\n",
    "\n",
    "# ==========\n",
    "#   MODEL\n",
    "# ==========\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_iters = 1000000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "seq_max_len = 20 # Sequence max length\n",
    "n_hidden = 64 # hidden layer num of features\n",
    "n_classes = 2 # linear sequence or not\n",
    "\n",
    "trainset = ToySequenceData(n_samples=1000, max_seq_len=seq_max_len)\n",
    "testset = ToySequenceData(n_samples=500, max_seq_len=seq_max_len)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, seq_max_len, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "# A placeholder for indicating each sequence length\n",
    "seqlen = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def dynamicRNN(x, seqlen, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "    \n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, seq_max_len, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # Get lstm cell output, providing 'sequence_length' will perform dynamic\n",
    "    # calculation.\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32,\n",
    "                                sequence_length=seqlen)\n",
    "\n",
    "    # When performing dynamic calculation, we must retrieve the last\n",
    "    # dynamically computed output, i.e., if a sequence length is 10, we need\n",
    "    # to retrieve the 10th output.\n",
    "    # However TensorFlow doesn't support advanced indexing yet, so we build\n",
    "    # a custom op that for each sample in batch size, get its length and\n",
    "    # get the corresponding relevant output.\n",
    "\n",
    "    # 'outputs' is a list of output at every timestep, we pack them in a Tensor\n",
    "    # and change back dimension to [batch_size, n_step, n_input]\n",
    "    outputs = tf.stack(outputs)\n",
    "    outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "\n",
    "    # Hack to build the indexing and retrieve the right output.\n",
    "    batch_size = tf.shape(outputs)[0]\n",
    "    # Start indices for each sample\n",
    "    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n",
    "    # Indexing\n",
    "    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n",
    "\n",
    "    # Linear activation, using outputs computed above\n",
    "    return tf.matmul(outputs, weights['out']) + biases['out']\n",
    "\n",
    "pred = dynamicRNN(x, seqlen, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y, batch_seqlen = trainset.next(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       seqlen: batch_seqlen})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y,\n",
    "                                                seqlen: batch_seqlen})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y,\n",
    "                                             seqlen: batch_seqlen})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_data = testset.data\n",
    "    test_label = testset.labels\n",
    "    test_seqlen = testset.seqlen\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label,\n",
    "seqlen: test_seqlen}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
